[32mINFO    [0m jubilant:_juju.py:237 cli: juju add-model --no-switch jubilant-51e4f0e9
[32mINFO    [0m jubilant:_juju.py:237 cli: juju deploy --model jubilant-51e4f0e9 ./haproxy_amd64.charm haproxy --base ubuntu@24.04
[32mINFO    [0m jubilant:_juju.py:237 cli: juju deploy --model jubilant-51e4f0e9 self-signed-certificates self-signed-certificates --channel 1/edge
[32mINFO    [0m jubilant:_juju.py:237 cli: juju config --model jubilant-51e4f0e9 haproxy external-hostname=haproxy.internal
[32mINFO    [0m jubilant:_juju.py:237 cli: juju integrate --model jubilant-51e4f0e9 haproxy:certificates self-signed-certificates:certificates
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
+ .model.name = 'jubilant-51e4f0e9'
+ .model.type = 'iaas'
+ .model.controller = 'github-pr-0020d-lxd'
+ .model.cloud = 'localhost'
+ .model.version = '3.6.11'
+ .model.region = 'localhost'
+ .model.model_status.current = 'available'
+ .machines['0'].juju_status.current = 'pending'
+ .machines['0'].instance_id = 'pending'
+ .machines['0'].machine_status.current = 'allocating'
+ .machines['0'].machine_status.message = 'Creating container'
+ .machines['0'].modification_status.current = 'idle'
+ .machines['0'].base.name = 'ubuntu'
+ .machines['0'].base.channel = '24.04'
+ .machines['0'].constraints = 'arch=amd64'
+ .machines['1'].juju_status.current = 'pending'
+ .machines['1'].instance_id = 'pending'
+ .machines['1'].machine_status.current = 'allocating'
+ .machines['1'].machine_status.message = 'Creating container'
+ .machines['1'].modification_status.current = 'idle'
+ .machines['1'].base.name = 'ubuntu'
+ .machines['1'].base.channel = '24.04'
+ .machines['1'].constraints = 'arch=amd64'
+ .apps['haproxy'].charm = 'local:haproxy-0'
+ .apps['haproxy'].charm_origin = 'local'
+ .apps['haproxy'].charm_name = 'haproxy'
+ .apps['haproxy'].charm_rev = 0
+ .apps['haproxy'].exposed = False
+ .apps['haproxy'].base.name = 'ubuntu'
+ .apps['haproxy'].base.channel = '24.04'
+ .apps['haproxy'].app_status.current = 'waiting'
+ .apps['haproxy'].app_status.message = 'waiting for machine'
+ .apps['haproxy'].relations['certificates'][0].related_app = 'self-signed-certificates'
+ .apps['haproxy'].relations['certificates'][0].interface = 'tls-certificates'
+ .apps['haproxy'].relations['certificates'][0].scope = 'global'
+ .apps['haproxy'].relations['haproxy-peers'][0].related_app = 'haproxy'
+ .apps['haproxy'].relations['haproxy-peers'][0].interface = 'haproxy-peers'
+ .apps['haproxy'].relations['haproxy-peers'][0].scope = 'global'
+ .apps['haproxy'].units['haproxy/0'].workload_status.current = 'waiting'
+ .apps['haproxy'].units['haproxy/0'].workload_status.message = 'waiting for machine'
+ .apps['haproxy'].units['haproxy/0'].juju_status.current = 'allocating'
+ .apps['haproxy'].units['haproxy/0'].machine = '0'
+ .apps['haproxy'].endpoint_bindings[''] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['certificates'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['cos-agent'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['ha'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['haproxy-peers'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['haproxy-route'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['haproxy-route-tcp'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['ingress'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['ingress-per-unit'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['receive-ca-certs'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['reverseproxy'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['website'] = 'alpha'
+ .apps['self-signed-certificates'].charm = 'self-signed-certificates'
+ .apps['self-signed-certificates'].charm_origin = 'charmhub'
+ .apps['self-signed-certificates'].charm_name = 'self-signed-certificates'
+ .apps['self-signed-certificates'].charm_rev = 416
+ .apps['self-signed-certificates'].exposed = False
+ .apps['self-signed-certificates'].base.name = 'ubuntu'
+ .apps['self-signed-certificates'].base.channel = '24.04'
+ .apps['self-signed-certificates'].charm_channel = '1/edge'
+ .apps['self-signed-certificates'].app_status.current = 'waiting'
+ .apps['self-signed-certificates'].app_status.message = 'waiting for machine'
+ .apps['self-signed-certificates'].relations['certificates'][0].related_app = 'haproxy'
+ .apps['self-signed-certificates'].relations['certificates'][0].interface = 'tls-certificates'
+ .apps['self-signed-certificates'].relations['certificates'][0].scope = 'global'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].workload_status.current = 'waiting'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].workload_status.message = 'waiting for machine'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.current = 'allocating'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].machine = '1'
+ .apps['self-signed-certificates'].endpoint_bindings[''] = 'alpha'
+ .apps['self-signed-certificates'].endpoint_bindings['certificates'] = 'alpha'
+ .apps['self-signed-certificates'].endpoint_bindings['send-ca-cert'] = 'alpha'
+ .apps['self-signed-certificates'].endpoint_bindings['tracing'] = 'alpha'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .machines['0'].instance_id = 'pending'
- .machines['0'].machine_status.current = 'allocating'
- .machines['0'].machine_status.message = 'Creating container'
- .machines['0'].modification_status.current = 'idle'
+ .machines['0'].instance_id = 'juju-844308-0'
+ .machines['0'].machine_status.current = 'running'
+ .machines['0'].machine_status.message = 'Container started'
+ .machines['0'].modification_status.current = 'applied'
+ .machines['0'].hardware = 'arch=amd64 cores=0 mem=0M availability-zone=github-runner virt-type=container'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .machines['0'].machine_status.message = 'Container started'
+ .machines['0'].machine_status.message = 'Running'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .machines['1'].instance_id = 'pending'
- .machines['1'].machine_status.current = 'allocating'
- .machines['1'].machine_status.message = 'Creating container'
- .machines['1'].modification_status.current = 'idle'
+ .machines['1'].instance_id = 'juju-844308-1'
+ .machines['1'].machine_status.current = 'running'
+ .machines['1'].machine_status.message = 'Container started'
+ .machines['1'].modification_status.current = 'applied'
+ .machines['1'].hardware = 'arch=amd64 cores=0 mem=0M availability-zone=github-runner virt-type=container'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
+ .machines['0'].dns_name = '10.139.41.26'
+ .machines['0'].ip_addresses[0] = '10.139.41.26'
+ .machines['1'].dns_name = '10.139.41.236'
+ .machines['1'].ip_addresses[0] = '10.139.41.236'
- .machines['1'].machine_status.message = 'Container started'
+ .machines['1'].machine_status.message = 'Running'
+ .apps['haproxy'].units['haproxy/0'].public_address = '10.139.41.26'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].public_address = '10.139.41.236'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .machines['0'].juju_status.current = 'pending'
+ .machines['0'].juju_status.current = 'started'
+ .machines['0'].juju_status.version = '3.6.11'
+ .machines['0'].hostname = 'juju-844308-0'
+ .machines['0'].network_interfaces['eth0'].ip_addresses[0] = '10.139.41.26'
+ .machines['0'].network_interfaces['eth0'].mac_address = '00:16:3e:9e:ab:84'
+ .machines['0'].network_interfaces['eth0'].is_up = True
+ .machines['0'].network_interfaces['eth0'].gateway = '10.139.41.1'
+ .machines['0'].network_interfaces['eth0'].space = 'alpha'
- .apps['haproxy'].app_status.message = 'waiting for machine'
+ .apps['haproxy'].app_status.message = 'agent initialising'
- .apps['haproxy'].units['haproxy/0'].workload_status.message = 'waiting for machine'
+ .apps['haproxy'].units['haproxy/0'].workload_status.message = 'agent initialising'
+ .apps['haproxy'].units['haproxy/0'].juju_status.version = '3.6.11'
+ .apps['haproxy'].units['haproxy/0'].leader = True
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .machines['1'].juju_status.current = 'pending'
+ .machines['1'].juju_status.current = 'started'
+ .machines['1'].juju_status.version = '3.6.11'
+ .machines['1'].hostname = 'juju-844308-1'
+ .machines['1'].network_interfaces['eth0'].ip_addresses[0] = '10.139.41.236'
+ .machines['1'].network_interfaces['eth0'].mac_address = '00:16:3e:4c:e5:c6'
+ .machines['1'].network_interfaces['eth0'].is_up = True
+ .machines['1'].network_interfaces['eth0'].gateway = '10.139.41.1'
+ .machines['1'].network_interfaces['eth0'].space = 'alpha'
- .apps['self-signed-certificates'].app_status.message = 'waiting for machine'
+ .apps['self-signed-certificates'].app_status.message = 'agent initialising'
- .apps['self-signed-certificates'].units['self-signed-certificates/0'].workload_status.message = 'waiting for machine'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].workload_status.message = 'agent initialising'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.version = '3.6.11'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].leader = True
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .apps['haproxy'].app_status.current = 'waiting'
- .apps['haproxy'].app_status.message = 'agent initialising'
+ .apps['haproxy'].app_status.current = 'maintenance'
+ .apps['haproxy'].app_status.message = 'installing charm software'
- .apps['haproxy'].units['haproxy/0'].workload_status.current = 'waiting'
- .apps['haproxy'].units['haproxy/0'].workload_status.message = 'agent initialising'
- .apps['haproxy'].units['haproxy/0'].juju_status.current = 'allocating'
+ .apps['haproxy'].units['haproxy/0'].workload_status.current = 'maintenance'
+ .apps['haproxy'].units['haproxy/0'].workload_status.message = 'installing charm software'
+ .apps['haproxy'].units['haproxy/0'].juju_status.current = 'executing'
+ .apps['haproxy'].units['haproxy/0'].juju_status.message = 'running install hook'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .apps['self-signed-certificates'].app_status.current = 'waiting'
- .apps['self-signed-certificates'].app_status.message = 'agent initialising'
+ .apps['self-signed-certificates'].app_status.current = 'maintenance'
+ .apps['self-signed-certificates'].app_status.message = 'installing charm software'
- .apps['self-signed-certificates'].units['self-signed-certificates/0'].workload_status.current = 'waiting'
- .apps['self-signed-certificates'].units['self-signed-certificates/0'].workload_status.message = 'agent initialising'
- .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.current = 'allocating'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].workload_status.current = 'maintenance'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].workload_status.message = 'installing charm software'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.current = 'executing'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.message = 'running install hook'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .apps['self-signed-certificates'].app_status.current = 'maintenance'
- .apps['self-signed-certificates'].app_status.message = 'installing charm software'
+ .apps['self-signed-certificates'].app_status.current = 'active'
- .apps['self-signed-certificates'].units['self-signed-certificates/0'].workload_status.current = 'maintenance'
- .apps['self-signed-certificates'].units['self-signed-certificates/0'].workload_status.message = 'installing charm software'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].workload_status.current = 'active'
- .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.message = 'running install hook'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.message = 'running certificates-relation-created hook'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.message = 'running certificates-relation-created hook'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.message = 'running config-changed hook'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .apps['haproxy'].app_status.message = 'installing charm software'
+ .apps['haproxy'].app_status.message = 'Configuring haproxy.'
- .apps['haproxy'].units['haproxy/0'].workload_status.message = 'installing charm software'
+ .apps['haproxy'].units['haproxy/0'].workload_status.message = 'Configuring haproxy.'
- .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.message = 'running config-changed hook'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.message = 'running start hook'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .apps['haproxy'].app_status.current = 'maintenance'
- .apps['haproxy'].app_status.message = 'Configuring haproxy.'
+ .apps['haproxy'].app_status.current = 'active'
- .apps['haproxy'].units['haproxy/0'].workload_status.current = 'maintenance'
- .apps['haproxy'].units['haproxy/0'].workload_status.message = 'Configuring haproxy.'
+ .apps['haproxy'].units['haproxy/0'].workload_status.current = 'active'
- .apps['haproxy'].units['haproxy/0'].juju_status.message = 'running install hook'
+ .apps['haproxy'].units['haproxy/0'].juju_status.message = 'running certificates-relation-created hook'
+ .apps['haproxy'].units['haproxy/0'].open_ports[0] = '80/tcp'
- .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.message = 'running start hook'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.message = 'running certificates-relation-changed hook for haproxy/0'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .apps['haproxy'].units['haproxy/0'].juju_status.message = 'running certificates-relation-created hook'
+ .apps['haproxy'].units['haproxy/0'].juju_status.message = 'running leader-elected hook'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .apps['haproxy'].app_status.current = 'active'
+ .apps['haproxy'].app_status.current = 'maintenance'
+ .apps['haproxy'].app_status.message = 'Configuring haproxy.'
- .apps['haproxy'].units['haproxy/0'].workload_status.current = 'active'
+ .apps['haproxy'].units['haproxy/0'].workload_status.current = 'maintenance'
+ .apps['haproxy'].units['haproxy/0'].workload_status.message = 'Configuring haproxy.'
- .apps['haproxy'].units['haproxy/0'].juju_status.message = 'running leader-elected hook'
+ .apps['haproxy'].units['haproxy/0'].juju_status.message = 'running config-changed hook'
- .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.current = 'executing'
- .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.message = 'running certificates-relation-changed hook for haproxy/0'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.current = 'idle'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .apps['haproxy'].app_status.current = 'maintenance'
- .apps['haproxy'].app_status.message = 'Configuring haproxy.'
+ .apps['haproxy'].app_status.current = 'active'
- .apps['haproxy'].units['haproxy/0'].workload_status.current = 'maintenance'
- .apps['haproxy'].units['haproxy/0'].workload_status.message = 'Configuring haproxy.'
+ .apps['haproxy'].units['haproxy/0'].workload_status.current = 'active'
- .apps['haproxy'].units['haproxy/0'].juju_status.message = 'running config-changed hook'
+ .apps['haproxy'].units['haproxy/0'].juju_status.message = 'running start hook'
- .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.current = 'idle'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.current = 'executing'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.message = 'running certificates-relation-changed hook for haproxy/0'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .apps['haproxy'].units['haproxy/0'].juju_status.message = 'running start hook'
+ .apps['haproxy'].units['haproxy/0'].juju_status.message = 'running certificates-relation-changed hook'
- .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.current = 'executing'
- .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.message = 'running certificates-relation-changed hook for haproxy/0'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.current = 'idle'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .apps['haproxy'].units['haproxy/0'].juju_status.message = 'running certificates-relation-changed hook'
+ .apps['haproxy'].units['haproxy/0'].juju_status.message = 'running certificates-relation-changed hook for self-signed-certificates/0'
[32mINFO    [0m jubilant:_juju.py:237 cli: juju deploy --model jubilant-51e4f0e9 any-charm any-charm-haproxy-route-tcp-requirer --channel beta --config 'src-overwrite={"any_charm.py": "# pylint: disable=import-error\n# Copyright 2025 Canonical Ltd.\n# See LICENSE file for licensing details.\n\n\"\"\"haproxy-route requirer source.\"\"\"\n\nimport logging\n\n# Ignoring import subprocess warning as we'"'"'re using it with no user inputs\nimport subprocess  # nosec\nimport textwrap\nfrom pathlib import Path\n\nimport ops\n\n# Ignoring here to make the linter happy as these modules will be available\n# only inside the anycharm unit.\nfrom any_charm_base import AnyCharmBase  # type: ignore\nfrom haproxy_route_tcp import HaproxyRouteTcpRequirer, TCPHealthCheckType  # type: ignore\n\nHAPROXY_ROUTE_TCP_RELATION = \"require-haproxy-route-tcp\"\n\nTLS_ROOT = \"/var/snap/ping-pong-tcp/common/\"\nCERT_PATH = f\"{TLS_ROOT}server.crt\"\nKEY_PATH = f\"{TLS_ROOT}server.key\"\nCNAME = \"example.com\"\n\nlogger = logging.getLogger()\n\n\nclass AnyCharm(AnyCharmBase):\n    \"\"\"haproxy-route requirer charm.\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        # We don'"'"'t need to include *args and *kwargs in the docstring here.\n        \"\"\"Initialize the requirer charm.\"\"\"  # noqa\n        super().__init__(*args, **kwargs)\n        self._haproxy_route_tcp = HaproxyRouteTcpRequirer(self, HAPROXY_ROUTE_TCP_RELATION)\n        self.framework.observe(self.on.config_changed, self.install)\n\n    def install(self, _: ops.EventBase):\n        \"\"\"Install TCP server snap.\"\"\"\n        Path(\"v3.ext\").write_text(\n            textwrap.dedent(\n                \"\"\"\n            authorityKeyIdentifier=keyid,issuer\n            basicConstraints=CA:FALSE\n            keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment\n            \"\"\"\n            ),\n            \"utf-8\",\n        )\n        command = (\n            \"openssl genrsa -out ca.key 4096; \"\n            \"openssl req -x509 -new -nodes -key ca.key -sha256 -days 1024 \"\n            f'"'"'-out ca.crt -subj \"/C=FR/ST=CA/O=, Inc./CN={CNAME}\"; '"'"'\n            \"openssl genrsa -out server.key 2048; \"\n            \"openssl req -new -sha256 -key server.key \"\n            f'"'"'-subj \"/C=FR/ST=P/O=, Inc./CN={CNAME}\" -out server.csr; '"'"'\n            \"openssl x509 -req -days 365 -in server.csr -extfile v3.ext \"\n            \"-CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt; \"\n            f\"cp server.crt server.key {TLS_ROOT}; \"\n            \"snap install ping-pong-tcp; \"\n            f\"snap set ping-pong-tcp host=0.0.0.0\"\n        )\n        # Ignoring subprocess warnings as we'"'"'re using it with no user inputs\n        subprocess.check_output([\"/bin/bash\", \"-c\", command])  # nosec\n        self.unit.status = ops.ActiveStatus(\"TCP server ready (TCP).\")\n\n    def start_tls(self):\n        \"\"\"Start server in TLS mode.\"\"\"\n        command = f\"snap set ping-pong-tcp tls.cert={CERT_PATH} tls.key={KEY_PATH}\"\n        # Ignoring subprocess warnings as we'"'"'re using it with no user inputs\n        subprocess.check_output([\"/bin/bash\", \"-c\", command])  # nosec\n        self.unit.status = ops.ActiveStatus(\"TCP server ready (TLS).\")\n\n    def start_tcp(self):\n        \"\"\"Start server in plaintext mode.\"\"\"\n        # Ignoring subprocess warnings as we'"'"'re using it with no user inputs\n        subprocess.check_output(\n            [\"/bin/bash\", \"-c\", \"snap unset ping-pong-tcp tls.cer tls.key\"]\n        )  # nosec\n        self.unit.status = ops.ActiveStatus(\"TCP server ready (TCP).\")\n\n    def update_relation(self):\n        \"\"\"Update haproxy-route-tcp relation data\"\"\"\n        self._haproxy_route_tcp.provide_haproxy_route_tcp_requirements(\n            port=4444,\n            backend_port=4000,\n            sni=CNAME,\n            check_type=TCPHealthCheckType.GENERIC,\n            check_interval=60,\n            check_rise=3,\n            check_fall=3,\n            check_send=\"ping\\r\\n\",\n            check_expect=\"pong\",\n        )\n", "haproxy_route_tcp.py": "# pylint: disable=too-many-lines,duplicate-code\n\"\"\"Haproxy-route interface library.\n\n## Getting Started\n\nTo get started using the library, you just need to fetch the library using `charmcraft`.\n\n```shell\ncd some-charm\ncharmcraft fetch-lib charms.haproxy.v1.haproxy_route_tcp\n```\n\nIn the `metadata.yaml` of the charm, add the following:\n\n```yaml\nrequires:\n    backend-tcp:\n        interface: haproxy-route-tcp\n        limit: 1\n```\n\nThen, to initialise the library:\n\n```python\nfrom charms.haproxy.v0.haproxy_route_tcp import HaproxyRouteTcpRequirer\n\nclass SomeCharm(CharmBase):\n  def __init__(self, *args):\n    # ...\n\n    # There are 2 ways you can use the requirer implementation:\n    # 1. To initialize the requirer with parameters:\n    self.haproxy_route_tcp_requirer = HaproxyRouteTcpRequirer(\n        self,\n        relation_name=\"haproxy-route-tcp\"\n        port=<optional>  # The port exposed on the provider.\n        backend_port=<optional>  # The port where the backend service is listening.\n        hosts=<optional>  # List of backend server addresses. Currently only support IP addresses.\n        sni=<optional>  # Server name identification. Used to route traffic to the service.\n        check_interval=<optional>  # Interval between health checks in seconds.\n        check_rise=<optional>  # Number of successful health checks\n            before server is considered up.\n        check_fall=<optional>  # Number of failed health checks before server is considered down.\n        check_type=<optional>  # Can be '"'"'generic'"'"', '"'"'mysql'"'"', '"'"'postgres'"'"', '"'"'redis'"'"' or '"'"'smtp'"'"'\u00df\u00df.\n        check_send=<optional>  # Only used in generic health checks,\n            specify a string to send in the health check request.\n        check_expect=<optional>  # Only used in generic health checks,\n            specify the expected response from a health check request.\n        check_db_user=<optional>  # Only used if type is postgres or mysql,\n            specify the user name to enable HAproxy to send a Client Authentication packet.\n        load_balancing_algorithm=<optional>  # Algorithm to use for load balancing.\n        load_balancing_consistent_hashing=<optional>  # Whether to use consistent hashing.\n        rate_limit_connections_per_minute=<optional>  # Maximum connections allowed per minute.\n        rate_limit_policy=<optional>  # Policy to apply when rate limit is reached.\n        upload_limit=<optional>  # Maximum upload bandwidth in bytes per second.\n        download_limit=<optional>  # Maximum download bandwidth in bytes per second.\n        retry_count=<optional>  # Number of times to retry failed requests.\n        retry_redispatch=<optional>  # Whether to redispatch failed requests to another server.\n        server_timeout=<optional>  # Timeout for requests from haproxy\n            to backend servers in seconds.\n        connect_timeout=<optional>  # Timeout for client requests to haproxy in seconds.\n        queue_timeout=<optional>  # Timeout for requests waiting in queue in seconds.\n        server_maxconn=<optional>  # Maximum connections per server.\n        ip_deny_list=<optional>  # List of source IP addresses to block.\n        enforce_tls=<optional>  # Whether to enforce TLS for all traffic coming to the backend.\n        tls_terminate=<optional>  # Whether to enable tls termination on the dedicated frontend.\n        unit_address=<optional>  # IP address of the unit\n            (if not provided, will use binding address).\n    )\n\n    # 2.To initialize the requirer with no parameters, i.e\n    # self.haproxy_route_tcp_requirer = HaproxyRouteTcpRequirer(self)\n    # This will simply initialize the requirer class and it won'"'"'t perfom any action.\n\n    # Afterwards regardless of how you initialized the requirer you can call the\n    # provide_haproxy_route_requirements method anywhere in your charm to update the requirer data.\n    # The method takes the same number of parameters as the requirer class.\n    # provide_haproxy_route_tcp_requirements(port=, ...)\n\n    self.framework.observe(\n        self.framework.on.config_changed, self._on_config_changed\n    )\n    self.framework.observe(\n        self.haproxy_route_tcp_requirer.on.ready, self._on_endpoints_ready\n    )\n    self.framework.observe(\n        self.haproxy_route_tcp_requirer.on.removed, self._on_endpoints_removed\n    )\n\n    def _on_config_changed(self, event: ConfigChangedEvent) -> None:\n        self.haproxy_route_tcp_requirer.provide_haproxy_route_tcp_requirements(...)\n\n    def _on_endpoints_ready(self, _: EventBase) -> None:\n        # Handle endpoints ready event\n        if endpoints := self.haproxy_route_tcp_requirer.get_proxied_endpoints():\n            # Do something with the endpoints information\n        ...\n\n    def _on_endpoints_removed(self, _: EventBase) -> None:\n        # Handle endpoints removed event\n        ...\n\n    # 3.To initialize the requirer together with helper methods.\n    # This will use chaining of the helper methods to populate the requirer\n    # data attributes.\n    self.haproxy_tcp_route_requirer = HaproxyRouteTcpRequirer(self, relation_name=\"\") \\\n        .configure_port(4000) \\\n        .configure_backend_port(5000) \\\n        .configure_health_check(60, 5, 5) \\\n        .configure_rate_limit(10, TCPRateLimitPolicy.SILENT) \\\n        .update_relation_data()\n\n\n## Using the library as the provider\nThe provider charm should expose the interface as shown below:\n```yaml\nprovides:\n    haproxy-route-tcp:\n        interface: haproxy-route-tcp\n```\nNote that this interface supports relating to multiple endpoints.\n\nThen, to initialise the library:\n```python\nfrom charms.haproxy.v0.haproxy_route import HaproxyRouteTcpProvider\n\nclass SomeCharm(CharmBase):\n    self.haproxy_route_tcp_provider = HaproxyRouteTcpProvider(self)\n    self.framework.observe(\n        self.haproxy_route_tcp_provider.on.data_available, self._on_haproxy_route_data_available\n    )\n\n    def _on_haproxy_route_data_available(self, event: EventBase) -> None:\n        data = self.haproxy_route_tcp_provider.get_data(self.haproxy_route_tcp_provider.relations)\n        # data is an object of the `HaproxyRouteTcpRequirersData` class, see below for the\n        # available attributes\n        ...\n\n        # Publish the endpoints to the requirers\n        for requirer_data in data.requirers_data:\n            self.haproxy_route_tcp.publish_proxied_endpoints(\n                [\"...\"], requirer_data.relation_id\n            )\n\"\"\"\n\nimport json\nimport logging\nfrom collections import defaultdict\nfrom enum import Enum\nfrom typing import Annotated, Any, MutableMapping, Optional, cast\n\nfrom ops import CharmBase, ModelError, RelationBrokenEvent\nfrom ops.charm import CharmEvents\nfrom ops.framework import EventBase, EventSource, Object\nfrom ops.model import Relation\nfrom pydantic import (\n    AnyUrl,\n    BaseModel,\n    BeforeValidator,\n    ConfigDict,\n    Field,\n    IPvAnyAddress,\n    ValidationError,\n    model_validator,\n)\nfrom pydantic.dataclasses import dataclass\nfrom typing_extensions import Self\n\n# The unique Charmhub library identifier, never change it\nLIBID = \"b1b5c0a6f1b5481c9923efa042846681\"\n\n# Increment this major API version when introducing breaking changes\nLIBAPI = 0\n\n# Increment this PATCH version before using `charmcraft publish-lib` or reset\n# to 0 if you are raising the major API version\nLIBPATCH = 1\n\nlogger = logging.getLogger(__name__)\nHAPROXY_ROUTE_TCP_RELATION_NAME = \"haproxy-route-tcp\"\nHAPROXY_CONFIG_INVALID_CHARACTERS = \"\\n\\t#\\\\'"'"'\\\"\\r$ \"\n\n\ndef value_contains_invalid_characters(value: Optional[str]) -> Optional[str]:\n    \"\"\"Validate if value contains invalid haproxy config characters.\n\n    Args:\n        value: The value to validate.\n\n    Raises:\n        ValueError: When value contains invalid characters.\n\n    Returns:\n        The validated value.\n    \"\"\"\n    if value is None:\n        return value\n\n    if [char for char in value if char in HAPROXY_CONFIG_INVALID_CHARACTERS]:\n        raise ValueError(f\"Relation data contains invalid character(s) {value}\")\n    return value\n\n\nVALIDSTR = Annotated[str, BeforeValidator(value_contains_invalid_characters)]\n\n\nclass DataValidationError(Exception):\n    \"\"\"Raised when data validation fails.\"\"\"\n\n\nclass HaproxyRouteTcpInvalidRelationDataError(Exception):\n    \"\"\"Raised when data validation of the haproxy-route relation fails.\"\"\"\n\n\nclass _DatabagModel(BaseModel):\n    \"\"\"Base databag model.\n\n    Attrs:\n        model_config: pydantic model configuration.\n    \"\"\"\n\n    model_config = ConfigDict(\n        # tolerate additional keys in databag\n        extra=\"ignore\",\n        # Allow instantiating this class by field name (instead of forcing alias).\n        populate_by_name=True,\n        # Custom config key: whether to nest the whole datastructure (as json)\n        # under a field or spread it out at the toplevel.\n        _NEST_UNDER=None,\n    )  # type: ignore\n    \"\"\"Pydantic config.\"\"\"\n\n    @classmethod\n    def load(cls, databag: MutableMapping) -> \"_DatabagModel\":\n        \"\"\"Load this model from a Juju json databag.\n\n        Args:\n            databag: Databag content.\n\n        Raises:\n            DataValidationError: When model validation failed.\n\n        Returns:\n            _DatabagModel: The validated model.\n        \"\"\"\n        nest_under = cls.model_config.get(\"_NEST_UNDER\")\n        if nest_under:\n            return cls.model_validate(json.loads(databag[nest_under]))\n\n        try:\n            data = {\n                k: json.loads(v)\n                for k, v in databag.items()\n                # Don'"'"'t attempt to parse model-external values\n                if k in {(f.alias or n) for n, f in cls.model_fields.items()}\n            }\n        except json.JSONDecodeError as e:\n            msg = f\"invalid databag contents: expecting json. {databag}\"\n            logger.error(msg)\n            raise DataValidationError(msg) from e\n\n        try:\n            return cls.model_validate_json(json.dumps(data))\n        except ValidationError as e:\n            msg = f\"failed to validate databag: {databag}\"\n            logger.error(str(e), exc_info=True)\n            raise DataValidationError(msg) from e\n\n    @classmethod\n    def from_dict(cls, values: dict) -> \"_DatabagModel\":\n        \"\"\"Load this model from a dict.\n\n        Args:\n            values: Dict values.\n\n        Raises:\n            DataValidationError: When model validation failed.\n\n        Returns:\n            _DatabagModel: The validated model.\n        \"\"\"\n        try:\n            logger.info(\"Loading values from dictionary: %s\", values)\n            return cls.model_validate(values)\n        except ValidationError as e:\n            msg = f\"failed to validate: {values}\"\n            logger.debug(msg, exc_info=True)\n            raise DataValidationError(msg) from e\n\n    def dump(\n        self, databag: Optional[MutableMapping] = None, clear: bool = True\n    ) -> Optional[MutableMapping]:\n        \"\"\"Write the contents of this model to Juju databag.\n\n        Args:\n            databag: The databag to write to.\n            clear: Whether to clear the databag before writing.\n\n        Returns:\n            MutableMapping: The databag.\n        \"\"\"\n        if clear and databag:\n            databag.clear()\n\n        if databag is None:\n            databag = {}\n        nest_under = self.model_config.get(\"_NEST_UNDER\")\n        if nest_under:\n            databag[nest_under] = self.model_dump_json(\n                by_alias=True,\n                # skip keys whose values are default\n                exclude_defaults=True,\n            )\n            return databag\n\n        dct = self.model_dump(mode=\"json\", by_alias=True, exclude_defaults=True)\n        databag.update({k: json.dumps(v) for k, v in dct.items()})\n        return databag\n\n\nclass TCPHealthCheckType(Enum):\n    \"\"\"Enum of possible rate limiting policies.\n\n    Attrs:\n        GENERIC: deny a client'"'"'s HTTP request to return a 403 Forbidden error.\n        MYSQL: closes the connection immediately without sending a response.\n        POSTGRES: disconnects immediately without notifying the client\n            that the connection has been closed.\n        REDIS: closes the connection immediately without sending a response.\n        SMTP: closes the connection immediately without sending a response.\n    \"\"\"\n\n    GENERIC = \"generic\"\n    MYSQL = \"mysql\"\n    POSTGRES = \"postgres\"\n    REDIS = \"redis\"\n    SMTP = \"smtp\"\n\n\nclass TCPServerHealthCheck(BaseModel):\n    \"\"\"Configuration model for backend server health checks.\n\n    Attributes:\n        interval: Number of seconds between consecutive health check attempts.\n        rise: Number of consecutive successful health checks required for up.\n        fall: Number of consecutive failed health checks required for DOWN.\n        check_type: Health check type, Can be \u201cgeneric\u201d, \u201cmysql\u201d, \u201cpostgres\u201d, \u201credis\u201d or \u201csmtp\u201d.\n        send: Only used in generic health checks,\n            specify a string to send in the health check request.\n        expect: Only used in generic health checks,\n            specify the expected response from a health check request.\n        db_user: Only used if type is postgres or mysql,\n            specify the user name to enable HAproxy to send a Client Authentication packet.\n    \"\"\"\n\n    # interval, rise and fall don'"'"'t have a default value since the class itself is optional\n    # in the requirer databag model, so once the class is instantiated we need all of the\n    # required attributes to be present as we can assume that health-check is being configured.\n    interval: int = Field(\n        description=\"The interval (in seconds) between health checks.\",\n        gt=0,\n    )\n    rise: int = Field(\n        description=\"How many successful health checks before server is considered up.\",\n        gt=0,\n    )\n    fall: int = Field(\n        description=\"How many failed health checks before server is considered down.\", gt=0\n    )\n    check_type: Optional[TCPHealthCheckType] = Field(\n        description=(\n            \"The health check type, can be '"'"'generic'"'"', '"'"'mysql'"'"', '"'"'postgres'"'"', '"'"'redis'"'"' or '"'"'smtp'"'"'\"\n        ),\n        default=None,\n    )\n    # send and expect does not have VALIDSTR validation because we need the flexibilty to\n    # specify anything in the health-check TCP requests. They will need to be properly\n    # sanitized / validated in the provider charm.\n    send: Optional[str] = Field(\n        description=(\n            \"Only used in generic health checks, \"\n            \"specify a string to send in the health check request.\"\n        ),\n        default=None,\n    )\n    expect: Optional[str] = Field(\n        description=(\n            \"Only used in generic health checks, \"\n            \"specify the expected response from a health check request.\"\n        ),\n        default=None,\n    )\n    db_user: Optional[VALIDSTR] = Field(\n        description=(\n            \"Only used if type is postgres or mysql, \"\n            \"specify the user name to enable HAproxy to send a Client Authentication packet.\"\n        ),\n        default=None,\n    )\n\n    @model_validator(mode=\"after\")\n    def check_all_required_fields_set(self) -> Self:\n        \"\"\"Check that all required fields for health check are set.\n\n        Raises:\n            ValueError: When validation fails.\n\n        Returns:\n            The validated model.\n        \"\"\"\n        if (\n            self.send is not None or self.expect is not None\n        ) and self.check_type != TCPHealthCheckType.GENERIC:\n            raise ValueError(\"send and expect can only be set if type is '"'"'generic'"'"'\")\n        if self.db_user is not None and self.check_type not in [\n            TCPHealthCheckType.MYSQL,\n            TCPHealthCheckType.POSTGRES,\n        ]:\n            raise ValueError(\"db_user can only be set if type is postgres or mysql\")\n        return self\n\n\n# tarpit is not yet implemented\nclass TCPRateLimitPolicy(Enum):\n    \"\"\"Enum of possible rate limiting policies.\n\n    Attrs:\n        REJECT: Send a TCP reset packet to close the connection.\n        SILENT: disconnects immediately without notifying the client\n            that the connection has been closed (no packet sent).\n    \"\"\"\n\n    REJECT = \"reject\"\n    SILENT = \"silent-drop\"\n\n\nclass RateLimit(BaseModel):\n    \"\"\"Configuration model for connection rate limiting.\n\n    Attributes:\n        connections_per_minute: Number of connections allowed per minute for a client.\n        policy: Action to take when the rate limit is exceeded.\n    \"\"\"\n\n    connections_per_minute: int = Field(description=\"How many connections are allowed per minute.\")\n    policy: TCPRateLimitPolicy = Field(\n        description=\"Configure the rate limit policy.\", default=TCPRateLimitPolicy.REJECT\n    )\n\n\nclass LoadBalancingAlgorithm(Enum):\n    \"\"\"Enum of possible http_route types.\n\n    Attrs:\n        LEASTCONN: The server with the lowest number of connections receives the connection.\n        SRCIP: Load balance using the hash of The source IP address.\n        ROUNDROBIN: Each server is used in turns, according to their weights.\n    \"\"\"\n\n    LEASTCONN = \"leastconn\"\n    SRCIP = \"source\"\n    ROUNDROBIN = \"roundrobin\"\n\n\nclass TCPLoadBalancingConfiguration(BaseModel):\n    \"\"\"Configuration model for load balancing.\n\n    Attributes:\n        algorithm: Algorithm to use for load balancing.\n        consistent_hashing: Use consistent hashing to avoid redirection\n            when servers are added/removed.\n    \"\"\"\n\n    algorithm: LoadBalancingAlgorithm = Field(\n        description=\"Configure the load balancing algorithm for the service.\",\n    )\n    # Note: Later when the generic LoadBalancingAlgorithm.HASH is implemented this attribute\n    # will also apply under that mode.\n    consistent_hashing: bool = Field(\n        description=(\n            \"Only used when the `algorithm` is SRCIP. \"\n            \"Use consistent hashing to avoid redirection when servers are added/removed. \"\n            \"Default is False as it usually does not give a balanced distribution.\"\n        ),\n        default=False,\n    )\n\n    @model_validator(mode=\"after\")\n    def validate_attributes(self) -> Self:\n        \"\"\"Check that algorithm-specific configs are only set with their respective algorithm.\n\n        Raises:\n            ValueError: When validation fails in one of these cases:\n                1. self.cookie is not None when self.algorithm != COOKIE\n                2. self.consistent_hashing is True when algorithm is neither COOKIE nor SRCIP\n\n        Returns:\n            The validated model.\n        \"\"\"\n        if self.consistent_hashing and self.algorithm != LoadBalancingAlgorithm.SRCIP:\n            raise ValueError(\"Consistent hashing only applies when algorithm is COOKIE or SRCIP.\")\n        return self\n\n\nclass BandwidthLimit(BaseModel):\n    \"\"\"Configuration model for bandwidth rate limiting.\n\n    Attributes:\n        upload: Limit upload speed (bytes per second).\n        download: Limit download speed (bytes per second).\n    \"\"\"\n\n    upload: Optional[int] = Field(description=\"Upload limit (bytes per seconds).\", default=None)\n    download: Optional[int] = Field(\n        description=\"Download limit (bytes per seconds).\", default=None\n    )\n\n\n# retry-on is not yet implemented\nclass Retry(BaseModel):\n    \"\"\"Configuration model for retry.\n\n    Attributes:\n        count: How many times should a request retry.\n        redispatch: Whether to redispatch failed requests to another server.\n    \"\"\"\n\n    count: int = Field(description=\"How many times should a request retry.\")\n    redispatch: bool = Field(\n        description=\"Whether to redispatch failed requests to another server.\", default=False\n    )\n\n\nclass TimeoutConfiguration(BaseModel):\n    \"\"\"Configuration model for timeout.\n\n    Attributes:\n        server: Timeout for requests from haproxy to backend servers.\n        connect: Timeout for client requests to haproxy.\n        queue: Timeout for requests waiting in the queue after server-maxconn is reached.\n    \"\"\"\n\n    server: Optional[int] = Field(\n        description=\"Timeout (in seconds) for requests from haproxy to backend servers.\",\n    )\n    connect: Optional[int] = Field(\n        description=\"Timeout (in seconds) for client requests to haproxy.\",\n    )\n    queue: Optional[int] = Field(\n        description=\"Timeout (in seconds) for requests in the queue.\",\n    )\n\n\nclass TcpRequirerApplicationData(_DatabagModel):\n    \"\"\"Configuration model for HAProxy route requirer application data.\n\n    Attributes:\n        port: The port exposed on the provider.\n        backend_port: The port where the backend service is listening. Defaults to the\n            provider port.\n        hosts: List of backend server addresses. Currently only support IP addresses.\n        sni: Server name identification. Used to route traffic to the service.\n        check: TCP health check configuration\n        load_balancing: Load balancing configuration.\n        rate_limit: Rate limit configuration.\n        bandwidth_limit: Bandwith limit configuration.\n        retry: Retry configuration.\n        timeout: Timeout configuration.\n        server_maxconn: Maximum connections per server.\n        ip_deny_list: List of source IP addresses to block.\n        enforce_tls: Whether to enforce TLS for all traffic coming to the backend.\n        tls_terminate: Whether to enable tls termination on the dedicated frontend.\n    \"\"\"\n\n    port: int = Field(description=\"The port exposed on the provider.\", gt=0, le=65535)\n    backend_port: Optional[int] = Field(\n        description=(\n            \"The port where the backend service is listening. \" \"Defaults to the provider port.\"\n        ),\n        default=None,\n        gt=0,\n        le=65525,\n    )\n    sni: Optional[VALIDSTR] = Field(\n        description=(\n            \"Server name identification. Used to route traffic to the service. \"\n            \"Only available if TLS is enabled.\"\n        ),\n        default=None,\n    )\n    hosts: list[IPvAnyAddress] = Field(\n        description=\"The list of backend server addresses. Currently only support IP addresses.\",\n        default=[],\n    )\n    check: Optional[TCPServerHealthCheck] = Field(\n        description=\"Configure health check for the service.\",\n        default=None,\n    )\n    load_balancing: Optional[TCPLoadBalancingConfiguration] = Field(\n        description=\"Configure loadbalancing.\", default=None\n    )\n    rate_limit: Optional[RateLimit] = Field(\n        description=\"Configure rate limit for the service.\", default=None\n    )\n    bandwidth_limit: Optional[BandwidthLimit] = Field(\n        description=\"Configure bandwidth limit for the service.\", default=None\n    )\n    retry: Optional[Retry] = Field(\n        description=\"Configure retry for incoming requests.\", default=None\n    )\n    timeout: Optional[TimeoutConfiguration] = Field(\n        description=\"Configure timeout\",\n        default=None,\n    )\n    server_maxconn: Optional[int] = Field(\n        description=\"Configure maximum connection per server\", default=None\n    )\n    ip_deny_list: list[IPvAnyAddress] = Field(\n        description=\"List of IP addresses to block.\", default=[]\n    )\n    enforce_tls: bool = Field(description=\"Whether to enforce TLS for all traffic.\", default=True)\n    tls_terminate: bool = Field(description=\"Whether to enable tls termination.\", default=True)\n\n    @model_validator(mode=\"after\")\n    def assign_default_backend_port(self) -> \"Self\":\n        \"\"\"Assign a default value to backend_port if not set.\n\n        The value is equal to the provider port.\n\n        Returns:\n            The model with backend_port default value applied.\n        \"\"\"\n        if self.backend_port is None:\n            self.backend_port = self.port\n        return self\n\n    @model_validator(mode=\"after\")\n    def sni_set_when_not_enforcing_tls(self) -> \"Self\":\n        \"\"\"Check if sni is configured but TLS is disabled.\n\n        Raises:\n            ValueError: If sni is configured and TLS is disabled.\n\n        Returns:\n            The validated model.\n        \"\"\"\n        if not self.enforce_tls and self.sni is not None:\n            raise ValueError(\"You can'"'"'t set SNI and disable TLS at the same time.\")\n        return self\n\n\nclass HaproxyRouteTcpProviderAppData(_DatabagModel):\n    \"\"\"haproxy-route provider databag schema.\n\n    Attributes:\n        endpoints: The list of proxied endpoints that maps to the backend.\n    \"\"\"\n\n    endpoints: list[AnyUrl]\n\n\nclass TcpRequirerUnitData(_DatabagModel):\n    \"\"\"haproxy-route requirer unit data.\n\n    Attributes:\n        address: IP address of the unit.\n    \"\"\"\n\n    address: IPvAnyAddress = Field(description=\"IP address of the unit.\")\n\n\n@dataclass\nclass HaproxyRouteTcpRequirerData:\n    \"\"\"haproxy-route requirer data.\n\n    Attributes:\n        relation_id: Id of the relation.\n        application: Name of the requirer application.\n        application_data: Application data.\n        units_data: Units data\n    \"\"\"\n\n    relation_id: int\n    application: str\n    application_data: TcpRequirerApplicationData\n    units_data: list[TcpRequirerUnitData]\n\n\n@dataclass\nclass HaproxyRouteTcpRequirersData:\n    \"\"\"haproxy-route requirers data.\n\n    Attributes:\n        requirers_data: List of requirer data.\n        relation_ids_with_invalid_data: List of relation ids that contains invalid data.\n    \"\"\"\n\n    requirers_data: list[HaproxyRouteTcpRequirerData]\n    relation_ids_with_invalid_data: list[int]\n\n    @model_validator(mode=\"after\")\n    def check_ports_unique(self) -> Self:\n        \"\"\"Check that requirers define unique ports.\n\n        Returns:\n            The validated model, with invalid relation IDs updated in\n                `self.relation_ids_with_invalid_data`\n        \"\"\"\n        # Maybe the logic here can be optimized, we want to keep track of\n        # the relation IDs that request overlapping ports to ignore them during\n        # rendering of the haproxy configuration.\n        relation_ids_per_port: dict[int, list[int]] = defaultdict(list[int])\n        for requirer_data in self.requirers_data:\n            relation_ids_per_port[requirer_data.application_data.port].append(\n                requirer_data.relation_id\n            )\n\n        for relation_ids in relation_ids_per_port.values():\n            if len(relation_ids) > 1:\n                self.relation_ids_with_invalid_data.extend(relation_ids)\n        return self\n\n\nclass HaproxyRouteTcpDataAvailableEvent(EventBase):\n    \"\"\"HaproxyRouteDataAvailableEvent custom event.\n\n    This event indicates that the requirers data are available.\n    \"\"\"\n\n\nclass HaproxyRouteTcpDataRemovedEvent(EventBase):\n    \"\"\"HaproxyRouteDataRemovedEvent custom event.\n\n    This event indicates that one of the endpoints was removed.\n    \"\"\"\n\n\nclass HaproxyRouteTcpProviderEvents(CharmEvents):\n    \"\"\"List of events for the haproxy-route TCP provider.\n\n    Attributes:\n        data_available: This event indicates that\n            the haproxy-route endpoints are available.\n        data_removed: This event indicates that one of the endpoints was removed.\n    \"\"\"\n\n    data_available = EventSource(HaproxyRouteTcpDataAvailableEvent)\n    data_removed = EventSource(HaproxyRouteTcpDataRemovedEvent)\n\n\nclass HaproxyRouteTcpProvider(Object):\n    \"\"\"Haproxy-route interface provider implementation.\n\n    Attributes:\n        on: Custom events of the provider.\n        relations: Related appliations.\n    \"\"\"\n\n    on = HaproxyRouteTcpProviderEvents()\n\n    def __init__(\n        self,\n        charm: CharmBase,\n        relation_name: str = HAPROXY_ROUTE_TCP_RELATION_NAME,\n        raise_on_validation_error: bool = False,\n    ) -> None:\n        \"\"\"Initialize the HaproxyRouteProvider.\n\n        Args:\n            charm: The charm that is instantiating the library.\n            relation_name: The name of the relation.\n            raise_on_validation_error: Whether the library should raise\n                HaproxyRouteTcpInvalidRelationDataError when requirer data validation fails.\n                If this is set to True the provider charm needs to also catch and handle the\n                thrown exception.\n        \"\"\"\n        super().__init__(charm, relation_name)\n\n        self._relation_name = relation_name\n        self.charm = charm\n        self.raise_on_validation_error = raise_on_validation_error\n        on = self.charm.on\n        self.framework.observe(on[self._relation_name].relation_changed, self._configure)\n        self.framework.observe(on[self._relation_name].relation_broken, self._on_endpoint_removed)\n        self.framework.observe(\n            on[self._relation_name].relation_departed, self._on_endpoint_removed\n        )\n\n    @property\n    def relations(self) -> list[Relation]:\n        \"\"\"The list of Relation instances associated with this endpoint.\"\"\"\n        return list(self.charm.model.relations[self._relation_name])\n\n    def _configure(self, _event: EventBase) -> None:\n        \"\"\"Handle relation events.\"\"\"\n        if relations := self.relations:\n            # Only for data validation\n            _ = self.get_data(relations)\n            self.on.data_available.emit()\n\n    def _on_endpoint_removed(self, _: EventBase) -> None:\n        \"\"\"Handle relation broken/departed events.\"\"\"\n        self.on.data_removed.emit()\n\n    def get_data(self, relations: list[Relation]) -> HaproxyRouteTcpRequirersData:\n        \"\"\"Fetch requirer data.\n\n        Args:\n            relations: A list of Relation instances to fetch data from.\n\n        Raises:\n            HaproxyRouteTcpInvalidRelationDataError: When requirer data validation fails.\n\n        Returns:\n            HaproxyRouteRequirersData: Validated data from all haproxy-route requirers.\n        \"\"\"\n        requirers_data: list[HaproxyRouteTcpRequirerData] = []\n        relation_ids_with_invalid_data: list[int] = []\n        for relation in relations:\n            try:\n                application_data = self._get_requirer_application_data(relation)\n                units_data = self._get_requirer_units_data(relation)\n                haproxy_route_tcp_requirer_data = HaproxyRouteTcpRequirerData(\n                    application_data=application_data,\n                    units_data=units_data,\n                    relation_id=relation.id,\n                    application=relation.app.name,\n                )\n                requirers_data.append(haproxy_route_tcp_requirer_data)\n            except DataValidationError as exc:\n                if self.raise_on_validation_error:\n                    logger.error(\n                        \"haproxy-route-tcp data validation failed for relation %s: %s\",\n                        relation,\n                        str(exc),\n                    )\n                    raise HaproxyRouteTcpInvalidRelationDataError(\n                        f\"haproxy-route-tcp data validation failed for relation: {relation}\"\n                    ) from exc\n                relation_ids_with_invalid_data.append(relation.id)\n                continue\n        return HaproxyRouteTcpRequirersData(\n            requirers_data=requirers_data,\n            relation_ids_with_invalid_data=relation_ids_with_invalid_data,\n        )\n\n    def _get_requirer_units_data(self, relation: Relation) -> list[TcpRequirerUnitData]:\n        \"\"\"Fetch and validate the requirer'"'"'s units data.\n\n        Args:\n            relation: The relation to fetch unit data from.\n\n        Raises:\n            DataValidationError: When unit data validation fails.\n\n        Returns:\n            list[RequirerUnitData]: List of validated unit data from the requirer.\n        \"\"\"\n        requirer_units_data: list[TcpRequirerUnitData] = []\n\n        for unit in relation.units:\n            databag = relation.data.get(unit)\n            if not databag:\n                logger.error(\n                    \"Requirer unit data does not exist even though the unit is still present.\"\n                )\n                continue\n            try:\n                data = cast(TcpRequirerUnitData, TcpRequirerUnitData.load(databag))\n                requirer_units_data.append(data)\n            except DataValidationError:\n                logger.error(\"Invalid requirer application data for %s\", unit)\n                raise\n        return requirer_units_data\n\n    def _get_requirer_application_data(self, relation: Relation) -> TcpRequirerApplicationData:\n        \"\"\"Fetch and validate the requirer'"'"'s application databag.\n\n        Args:\n            relation: The relation to fetch application data from.\n\n        Raises:\n            DataValidationError: When requirer application data validation fails.\n\n        Returns:\n            RequirerApplicationData: Validated application data from the requirer.\n        \"\"\"\n        try:\n            return cast(\n                TcpRequirerApplicationData,\n                TcpRequirerApplicationData.load(relation.data[relation.app]),\n            )\n        except DataValidationError:\n            logger.error(\"Invalid requirer application data for %s\", relation.app.name)\n            raise\n\n    def publish_proxied_endpoints(self, endpoints: list[str], relation: Relation) -> None:\n        \"\"\"Publish to the app databag the proxied endpoints.\n\n        Args:\n            endpoints: The list of proxied endpoints to publish.\n            relation: The relation with the requirer application.\n        \"\"\"\n        HaproxyRouteTcpProviderAppData(\n            endpoints=[cast(AnyUrl, endpoint) for endpoint in endpoints]\n        ).dump(relation.data[self.charm.app], clear=True)\n\n\nclass HaproxyRouteTcpEnpointsReadyEvent(EventBase):\n    \"\"\"HaproxyRouteTcpEnpointsReadyEvent custom event.\"\"\"\n\n\nclass HaproxyRouteTcpEndpointsRemovedEvent(EventBase):\n    \"\"\"HaproxyRouteTcpEndpointsRemovedEvent custom event.\"\"\"\n\n\nclass HaproxyRouteTcpRequirerEvents(CharmEvents):\n    \"\"\"List of events that the TLS Certificates requirer charm can leverage.\n\n    Attributes:\n        ready: when the provider proxied endpoints are ready.\n        removed: when the provider\n    \"\"\"\n\n    ready = EventSource(HaproxyRouteTcpEnpointsReadyEvent)\n    removed = EventSource(HaproxyRouteTcpEndpointsRemovedEvent)\n\n\nclass HaproxyRouteTcpRequirer(Object):\n    \"\"\"haproxy-route interface requirer implementation.\n\n    Attributes:\n        on: Custom events of the requirer.\n    \"\"\"\n\n    on = HaproxyRouteTcpRequirerEvents()\n\n    # pylint: disable=too-many-arguments,too-many-positional-arguments,too-many-locals\n    def __init__(\n        self,\n        charm: CharmBase,\n        relation_name: str,\n        *,\n        port: Optional[int] = None,\n        backend_port: Optional[int] = None,\n        hosts: Optional[list[str]] = None,\n        sni: Optional[str] = None,\n        check_interval: Optional[int] = None,\n        check_rise: Optional[int] = None,\n        check_fall: Optional[int] = None,\n        check_type: Optional[TCPHealthCheckType] = None,\n        check_send: Optional[str] = None,\n        check_expect: Optional[str] = None,\n        check_db_user: Optional[str] = None,\n        load_balancing_algorithm: Optional[LoadBalancingAlgorithm] = None,\n        load_balancing_consistent_hashing: bool = False,\n        rate_limit_connections_per_minute: Optional[int] = None,\n        rate_limit_policy: TCPRateLimitPolicy = TCPRateLimitPolicy.REJECT,\n        upload_limit: Optional[int] = None,\n        download_limit: Optional[int] = None,\n        retry_count: Optional[int] = None,\n        retry_redispatch: bool = False,\n        server_timeout: Optional[int] = None,\n        connect_timeout: Optional[int] = None,\n        queue_timeout: Optional[int] = None,\n        server_maxconn: Optional[int] = None,\n        ip_deny_list: Optional[list[IPvAnyAddress]] = None,\n        enforce_tls: bool = True,\n        tls_terminate: bool = True,\n        unit_address: Optional[str] = None,\n    ) -> None:\n        \"\"\"Initialize the HaproxyRouteRequirer.\n\n        Args:\n            charm: The charm that is instantiating the library.\n            relation_name: The name of the relation to bind to.\n            port: The provider port.\n            backend_port: List of ports the service is listening on.\n            hosts: List of backend server addresses. Currently only support IP addresses.\n            sni: List of URL paths to route to this service.\n            check_interval: Interval between health checks in seconds.\n            check_rise: Number of successful health checks before server is considered up.\n            check_fall: Number of failed health checks before server is considered down.\n            check_type: Health check type,\n                Can be \u201cgeneric\u201d, \u201cmysql\u201d, \u201cpostgres\u201d, \u201credis\u201d or \u201csmtp\u201d.\n            check_send: Only used in generic health checks,\n                specify a string to send in the health check request.\n            check_expect: Only used in generic health checks,\n                specify the expected response from a health check request.\n            check_db_user: Only used if type is postgres or mysql,\n                specify the user name to enable HAproxy to send a Client Authentication packet.\n            load_balancing_algorithm: Algorithm to use for load balancing.\n            load_balancing_consistent_hashing: Whether to use consistent hashing.\n            rate_limit_connections_per_minute: Maximum connections allowed per minute.\n            rate_limit_policy: Policy to apply when rate limit is reached.\n            upload_limit: Maximum upload bandwidth in bytes per second.\n            download_limit: Maximum download bandwidth in bytes per second.\n            retry_count: Number of times to retry failed requests.\n            retry_redispatch: Whether to redispatch failed requests to another server.\n            server_timeout: Timeout for requests from haproxy to backend servers in seconds.\n            connect_timeout: Timeout for client requests to haproxy in seconds.\n            queue_timeout: Timeout for requests waiting in queue in seconds.\n            server_maxconn: Maximum connections per server.\n            ip_deny_list: List of source IP addresses to block.\n            enforce_tls: Whether to enforce TLS for all traffic coming to the backend.\n            tls_terminate: Whether to enable tls termination on the dedicated frontend.\n            unit_address: IP address of the unit (if not provided, will use binding address).\n        \"\"\"\n        super().__init__(charm, relation_name)\n\n        self._relation_name = relation_name\n        self.relation = self.model.get_relation(self._relation_name)\n        self.charm = charm\n        self.app = self.charm.app\n\n        # build the full application data\n        self._application_data = self._generate_application_data(\n            port=port,\n            backend_port=backend_port,\n            hosts=hosts,\n            sni=sni,\n            check_interval=check_interval,\n            check_rise=check_rise,\n            check_fall=check_fall,\n            check_type=check_type,\n            check_send=check_send,\n            check_expect=check_expect,\n            check_db_user=check_db_user,\n            load_balancing_algorithm=load_balancing_algorithm,\n            load_balancing_consistent_hashing=load_balancing_consistent_hashing,\n            rate_limit_connections_per_minute=rate_limit_connections_per_minute,\n            rate_limit_policy=rate_limit_policy,\n            upload_limit=upload_limit,\n            download_limit=download_limit,\n            retry_count=retry_count,\n            retry_redispatch=retry_redispatch,\n            server_timeout=server_timeout,\n            connect_timeout=connect_timeout,\n            queue_timeout=queue_timeout,\n            server_maxconn=server_maxconn,\n            ip_deny_list=ip_deny_list,\n            enforce_tls=enforce_tls,\n            tls_terminate=tls_terminate,\n        )\n        self._unit_address = unit_address\n\n        on = self.charm.on\n        self.framework.observe(on[self._relation_name].relation_created, self._configure)\n        self.framework.observe(on[self._relation_name].relation_changed, self._configure)\n        self.framework.observe(on[self._relation_name].relation_broken, self._on_relation_broken)\n\n    def _configure(self, _: EventBase) -> None:\n        \"\"\"Handle relation events.\"\"\"\n        self.update_relation_data()\n        if self.relation and self.get_proxied_endpoints():\n            # This event is only emitted when the provider databag changes\n            # which only happens when relevant changes happened\n            # Additionally this event is purely informational and it'"'"'s up to the requirer to\n            # fetch the proxied endpoints in their code using get_proxied_endpoints\n            self.on.ready.emit()\n\n    def _on_relation_broken(self, _: RelationBrokenEvent) -> None:\n        \"\"\"Handle relation broken event.\"\"\"\n        self.on.removed.emit()\n\n    # pylint: disable=too-many-arguments,too-many-positional-arguments\n    def provide_haproxy_route_tcp_requirements(\n        self,\n        *,\n        port: int,\n        backend_port: Optional[int] = None,\n        hosts: Optional[list[str]] = None,\n        sni: Optional[str] = None,\n        check_interval: Optional[int] = None,\n        check_rise: Optional[int] = None,\n        check_fall: Optional[int] = None,\n        check_type: Optional[TCPHealthCheckType] = None,\n        check_send: Optional[str] = None,\n        check_expect: Optional[str] = None,\n        check_db_user: Optional[str] = None,\n        load_balancing_algorithm: Optional[LoadBalancingAlgorithm] = None,\n        load_balancing_consistent_hashing: bool = False,\n        rate_limit_connections_per_minute: Optional[int] = None,\n        rate_limit_policy: TCPRateLimitPolicy = TCPRateLimitPolicy.REJECT,\n        upload_limit: Optional[int] = None,\n        download_limit: Optional[int] = None,\n        retry_count: Optional[int] = None,\n        retry_redispatch: bool = False,\n        server_timeout: Optional[int] = None,\n        connect_timeout: Optional[int] = None,\n        queue_timeout: Optional[int] = None,\n        server_maxconn: Optional[int] = None,\n        ip_deny_list: Optional[list[IPvAnyAddress]] = None,\n        enforce_tls: bool = True,\n        tls_terminate: bool = True,\n        unit_address: Optional[str] = None,\n    ) -> None:\n        \"\"\"Update haproxy-route requirements data in the relation.\n\n        Args:\n            port: The provider port.\n            backend_port: List of ports the service is listening on.\n            hosts: List of backend server addresses. Currently only support IP addresses.\n            sni: List of URL paths to route to this service.\n            check_interval: Interval between health checks in seconds.\n            check_rise: Number of successful health checks before server is considered up.\n            check_fall: Number of failed health checks before server is considered down.\n            check_type: Health check type,\n                Can be \u201cgeneric\u201d, \u201cmysql\u201d, \u201cpostgres\u201d, \u201credis\u201d or \u201csmtp\u201d.\n            check_send: Only used in generic health checks,\n                specify a string to send in the health check request.\n            check_expect: Only used in generic health checks,\n                specify the expected response from a health check request.\n            check_db_user: Only used if type is postgres or mysql,\n                specify the user name to enable HAproxy to send a Client Authentication packet.\n            load_balancing_algorithm: Algorithm to use for load balancing.\n            load_balancing_consistent_hashing: Whether to use consistent hashing.\n            rate_limit_connections_per_minute: Maximum connections allowed per minute.\n            rate_limit_policy: Policy to apply when rate limit is reached.\n            upload_limit: Maximum upload bandwidth in bytes per second.\n            download_limit: Maximum download bandwidth in bytes per second.\n            retry_count: Number of times to retry failed requests.\n            retry_redispatch: Whether to redispatch failed requests to another server.\n            server_timeout: Timeout for requests from haproxy to backend servers in seconds.\n            connect_timeout: Timeout for client requests to haproxy in seconds.\n            queue_timeout: Timeout for requests waiting in queue in seconds.\n            server_maxconn: Maximum connections per server.\n            ip_deny_list: List of source IP addresses to block.\n            enforce_tls: Whether to enforce TLS for all traffic coming to the backend.\n            tls_terminate: Whether to enable tls termination on the dedicated frontend.\n            unit_address: IP address of the unit (if not provided, will use binding address).\n        \"\"\"\n        self._unit_address = unit_address\n        self._application_data = self._generate_application_data(\n            port=port,\n            backend_port=backend_port,\n            hosts=hosts,\n            sni=sni,\n            check_interval=check_interval,\n            check_rise=check_rise,\n            check_fall=check_fall,\n            check_type=check_type,\n            check_send=check_send,\n            check_expect=check_expect,\n            check_db_user=check_db_user,\n            load_balancing_algorithm=load_balancing_algorithm,\n            load_balancing_consistent_hashing=load_balancing_consistent_hashing,\n            rate_limit_connections_per_minute=rate_limit_connections_per_minute,\n            rate_limit_policy=rate_limit_policy,\n            upload_limit=upload_limit,\n            download_limit=download_limit,\n            retry_count=retry_count,\n            retry_redispatch=retry_redispatch,\n            server_timeout=server_timeout,\n            connect_timeout=connect_timeout,\n            queue_timeout=queue_timeout,\n            server_maxconn=server_maxconn,\n            ip_deny_list=ip_deny_list,\n            enforce_tls=enforce_tls,\n            tls_terminate=tls_terminate,\n        )\n        self.update_relation_data()\n\n    # pylint: disable=too-many-arguments,too-many-positional-arguments,too-many-locals\n    def _generate_application_data(  # noqa: C901\n        self,\n        *,\n        port: Optional[int] = None,\n        backend_port: Optional[int] = None,\n        hosts: Optional[list[str]] = None,\n        sni: Optional[str] = None,\n        check_interval: Optional[int] = None,\n        check_rise: Optional[int] = None,\n        check_fall: Optional[int] = None,\n        check_type: Optional[TCPHealthCheckType] = None,\n        check_send: Optional[str] = None,\n        check_expect: Optional[str] = None,\n        check_db_user: Optional[str] = None,\n        load_balancing_algorithm: Optional[LoadBalancingAlgorithm] = None,\n        load_balancing_consistent_hashing: bool = False,\n        rate_limit_connections_per_minute: Optional[int] = None,\n        rate_limit_policy: TCPRateLimitPolicy = TCPRateLimitPolicy.REJECT,\n        upload_limit: Optional[int] = None,\n        download_limit: Optional[int] = None,\n        retry_count: Optional[int] = None,\n        retry_redispatch: bool = False,\n        server_timeout: Optional[int] = None,\n        connect_timeout: Optional[int] = None,\n        queue_timeout: Optional[int] = None,\n        server_maxconn: Optional[int] = None,\n        ip_deny_list: Optional[list[IPvAnyAddress]] = None,\n        enforce_tls: bool = True,\n        tls_terminate: bool = True,\n    ) -> dict[str, Any]:\n        \"\"\"Generate the complete application data structure.\n\n        Args:\n            port: The provider port.\n            backend_port: List of ports the service is listening on.\n            hosts: List of backend server addresses. Currently only support IP addresses.\n            sni: List of URL paths to route to this service.\n            check_interval: Interval between health checks in seconds.\n            check_rise: Number of successful health checks before server is considered up.\n            check_fall: Number of failed health checks before server is considered down.\n            check_type: Health check type,\n                Can be \u201cgeneric\u201d, \u201cmysql\u201d, \u201cpostgres\u201d, \u201credis\u201d or \u201csmtp\u201d.\n            check_send: Only used in generic health checks,\n                specify a string to send in the health check request.\n            check_expect: Only used in generic health checks,\n                specify the expected response from a health check request.\n            check_db_user: Only used if type is postgres or mysql,\n                specify the user name to enable HAproxy to send a Client Authentication packet.\n            load_balancing_algorithm: Algorithm to use for load balancing.\n            load_balancing_consistent_hashing: Whether to use consistent hashing.\n            rate_limit_connections_per_minute: Maximum connections allowed per minute.\n            rate_limit_policy: Policy to apply when rate limit is reached.\n            upload_limit: Maximum upload bandwidth in bytes per second.\n            download_limit: Maximum download bandwidth in bytes per second.\n            retry_count: Number of times to retry failed requests.\n            retry_redispatch: Whether to redispatch failed requests to another server.\n            server_timeout: Timeout for requests from haproxy to backend servers in seconds.\n            connect_timeout: Timeout for client requests to haproxy in seconds.\n            queue_timeout: Timeout for requests waiting in queue in seconds.\n            server_maxconn: Maximum connections per server.\n            ip_deny_list: List of source IP addresses to block.\n            enforce_tls: Whether to enforce TLS for all traffic coming to the backend.\n            tls_terminate: Whether to enable tls termination on the dedicated frontend.\n\n        Returns:\n            dict: A dictionary containing the complete application data structure.\n        \"\"\"\n        # Apply default value to list parameters to avoid problems with mutable default args.\n        if not hosts:\n            hosts = []\n        if not ip_deny_list:\n            ip_deny_list = []\n\n        application_data: dict[str, Any] = {\n            \"port\": port,\n            \"backend_port\": backend_port,\n            \"hosts\": hosts,\n            \"sni\": sni,\n            \"load_balancing\": self._generate_load_balancing_configuration(\n                load_balancing_algorithm, load_balancing_consistent_hashing\n            ),\n            \"check\": self._generate_server_health_check_configuration(\n                check_interval,\n                check_rise,\n                check_fall,\n                check_type,\n                check_send,\n                check_expect,\n                check_db_user,\n            ),\n            \"timeout\": self._generate_timeout_configuration(\n                server_timeout, connect_timeout, queue_timeout\n            ),\n            \"rate_limit\": self._generate_rate_limit_configuration(\n                rate_limit_connections_per_minute, rate_limit_policy\n            ),\n            \"bandwidth_limit\": {\n                \"download\": download_limit,\n                \"upload\": upload_limit,\n            },\n            \"retry\": self._generate_retry_configuration(retry_count, retry_redispatch),\n            \"ip_deny_list\": ip_deny_list,\n            \"server_maxconn\": server_maxconn,\n            \"enforce_tls\": enforce_tls,\n            \"tls_terminate\": tls_terminate,\n        }\n\n        return application_data\n\n    def _generate_server_health_check_configuration(\n        self,\n        interval: Optional[int],\n        rise: Optional[int],\n        fall: Optional[int],\n        check_type: Optional[TCPHealthCheckType],\n        send: Optional[str],\n        expect: Optional[str],\n        db_user: Optional[str],\n    ) -> Optional[dict[str, int | str | TCPHealthCheckType | None]]:\n        \"\"\"Generate configuration for server health checks.\n\n        Args:\n        interval: Number of seconds between consecutive health check attempts.\n        rise: Number of consecutive successful health checks required for up.\n        fall: Number of consecutive failed health checks required for DOWN.\n        check_type: Health check type, Can be \u201cgeneric\u201d, \u201cmysql\u201d, \u201cpostgres\u201d, \u201credis\u201d or \u201csmtp\u201d.\n        send: Only used in generic health checks,\n            specify a string to send in the health check request.\n        expect: Only used in generic health checks,\n            specify the expected response from a health check request.\n        db_user: Only used if type is postgres or mysql,\n            specify the user name to enable HAproxy to send a Client Authentication packet.\n\n        Returns:\n            Optional[dict[str, int | str | TCPHealthCheckType | None]]:\n                Health check configuration dictionary.\n        \"\"\"\n        if not (interval and rise and fall):\n            return None\n        return {\n            \"interval\": interval,\n            \"rise\": rise,\n            \"fall\": fall,\n            \"check_type\": check_type,\n            \"send\": send,\n            \"expect\": expect,\n            \"db_user\": db_user,\n        }\n\n    def _generate_rate_limit_configuration(\n        self,\n        connections_per_minute: Optional[int],\n        policy: TCPRateLimitPolicy,\n    ) -> Optional[dict[str, Any]]:\n        \"\"\"Generate rate limit configuration.\n\n        Args:\n            connections_per_minute: Maximum connections allowed per minute.\n            policy: Policy to apply when rate limit is reached.\n\n        Returns:\n            Optional[dict[str, Any]]: Rate limit configuration,\n                or None if required fields are not configured.\n        \"\"\"\n        if not connections_per_minute:\n            return None\n        return {\n            \"connections_per_minute\": connections_per_minute,\n            \"policy\": policy,\n        }\n\n    def _generate_timeout_configuration(\n        self,\n        server_timeout_in_seconds: Optional[int],\n        connect_timeout_in_seconds: Optional[int],\n        queue_timeout_in_seconds: Optional[int],\n    ) -> Optional[dict[str, Optional[int]]]:\n        \"\"\"Generate rate limit configuration.\n\n        Args:\n            server_timeout_in_seconds: Server timeout.\n            connect_timeout_in_seconds: Connect timeout.\n            queue_timeout_in_seconds: Queue timeout\n\n        Returns:\n            Optional[dict[str, Any]]: Rate limit configuration,\n                or None if required fields are not configured.\n        \"\"\"\n        if not (\n            server_timeout_in_seconds or connect_timeout_in_seconds or queue_timeout_in_seconds\n        ):\n            return None\n        return {\n            \"server\": server_timeout_in_seconds,\n            \"connect\": connect_timeout_in_seconds,\n            \"queue\": queue_timeout_in_seconds,\n        }\n\n    def _generate_retry_configuration(\n        self, count: Optional[int], redispatch: bool\n    ) -> Optional[dict[str, Any]]:\n        \"\"\"Generate retry configuration.\n\n        Args:\n            count: Number of times to retry failed requests.\n            redispatch: Whether to redispatch failed requests to another server.\n\n        Returns:\n            Optional[dict[str, Any]]: Retry configuration dictionary,\n                or None if required fields are not configured.\n        \"\"\"\n        if not count:\n            return None\n        return {\n            \"count\": count,\n            \"redispatch\": redispatch,\n        }\n\n    def _generate_load_balancing_configuration(\n        self, algorithm: Optional[LoadBalancingAlgorithm], consistent_hashing: bool\n    ) -> Optional[dict[str, Any]]:\n        \"\"\"Generate load balancing configuration.\n\n        Args:\n            algorithm: The load balancing algorithm.\n            consistent_hashing: Whether to use consistent hashing.\n\n        Returns:\n            Optional[dict[str, Any]]: Load balancing configuration dictionary,\n                or None if required fields are not configured.\n        \"\"\"\n        if not algorithm:\n            return None\n        return {\n            \"algorithm\": algorithm,\n            \"consistent_hashing\": consistent_hashing,\n        }\n\n    def update_relation_data(self) -> None:\n        \"\"\"Update both application and unit data in the relation.\"\"\"\n        if not self._application_data.get(\"port\"):\n            logger.warning(\"port must be set, skipping update.\")\n            return\n\n        if relation := self.relation:\n            self._update_application_data(relation)\n            self._update_unit_data(relation)\n\n    def _update_application_data(self, relation: Relation) -> None:\n        \"\"\"Update application data in the relation databag.\n\n        Args:\n            relation: The relation instance.\n        \"\"\"\n        if self.charm.unit.is_leader():\n            application_data = self._prepare_application_data()\n            application_data.dump(relation.data[self.app], clear=True)\n\n    def _update_unit_data(self, relation: Relation) -> None:\n        \"\"\"Prepare and update the unit data in the relation databag.\n\n        Args:\n            relation: The relation instance.\n        \"\"\"\n        unit_data = self._prepare_unit_data()\n        unit_data.dump(relation.data[self.charm.unit], clear=True)\n\n    def _prepare_application_data(self) -> TcpRequirerApplicationData:\n        \"\"\"Prepare and validate the application data.\n\n        Raises:\n            DataValidationError: When validation of application data fails.\n\n        Returns:\n            RequirerApplicationData: The validated application data model.\n        \"\"\"\n        try:\n            return cast(\n                TcpRequirerApplicationData,\n                TcpRequirerApplicationData.from_dict(self._application_data),\n            )\n        except ValidationError as exc:\n            logger.error(\"Validation error when preparing requirer application data.\")\n            raise DataValidationError(\n                \"Validation error when preparing requirer application data.\"\n            ) from exc\n\n    def _prepare_unit_data(self) -> TcpRequirerUnitData:\n        \"\"\"Prepare and validate unit data.\n\n        Raises:\n            DataValidationError: When no address or unit IP is available.\n\n        Returns:\n            RequirerUnitData: The validated unit data model.\n        \"\"\"\n        address = self._unit_address\n        if not address:\n            network_binding = self.charm.model.get_binding(\"juju-info\")\n            if (\n                network_binding is not None\n                and (bind_address := network_binding.network.bind_address) is not None\n            ):\n                address = str(bind_address)\n            else:\n                logger.error(\"No unit IP available.\")\n                raise DataValidationError(\"No unit IP available.\")\n        return TcpRequirerUnitData(address=cast(IPvAnyAddress, address))\n\n    def get_proxied_endpoints(self) -> list[AnyUrl]:\n        \"\"\"The full ingress URL to reach the current unit.\n\n        Returns:\n            The provider URL or None if the URL isn'"'"'t available yet or is not valid.\n        \"\"\"\n        relation = self.relation\n        if not relation or not relation.app:\n            return []\n\n        # Fetch the provider'"'"'s app databag\n        try:\n            databag = relation.data[relation.app]\n        except ModelError:\n            logger.exception(\"Error reading remote app data.\")\n            return []\n\n        if not databag:  # not ready yet\n            return []\n\n        try:\n            provider_data = cast(\n                HaproxyRouteTcpProviderAppData, HaproxyRouteTcpProviderAppData.load(databag)\n            )\n            return provider_data.endpoints\n        except DataValidationError:\n            logger.exception(\"Invalid provider url.\")\n            return []\n\n    # The following methods allows for chaining which aims to improve the developper experience\n    # The following methods allows for chaining which aims to improve the developper experience\n    def configure_port(self, port: int) -> \"Self\":\n        \"\"\"Set the provider port.\n\n        Args:\n            port: The provider port to set\n\n        Returns:\n            Self: The HaproxyRouteTcpRequirer class\n        \"\"\"\n        self._application_data[\"port\"] = port\n        return self\n\n    def configure_backend_port(self, backend_port: int) -> \"Self\":\n        \"\"\"Set the backend port.\n\n        Args:\n            backend_port: The backend port to set\n\n        Returns:\n            Self: The HaproxyRouteTcpRequirer class\n        \"\"\"\n        self._application_data[\"backend_port\"] = backend_port\n        return self\n\n    def configure_hosts(self, hosts: Optional[list[int]] = None) -> \"Self\":\n        \"\"\"Set backend hosts.\n\n        Args:\n            hosts: The hosts list to set\n\n        Returns:\n            Self: The HaproxyRouteTcpRequirer class\n        \"\"\"\n        if not hosts:\n            hosts = []\n        self._application_data[\"hosts\"] = hosts\n        return self\n\n    def configure_sni(self, sni: str) -> \"Self\":\n        \"\"\"Set the SNI.\n\n        Args:\n            sni: The SNI to set\n\n        Returns:\n            Self: The HaproxyRouteTcpRequirer class\n        \"\"\"\n        self._application_data[\"sni\"] = sni\n        return self\n\n    def configure_health_check(\n        self,\n        interval: int,\n        rise: int,\n        fall: int,\n        check_type: TCPHealthCheckType = TCPHealthCheckType.GENERIC,\n        send: Optional[str] = None,\n        expect: Optional[str] = None,\n        db_user: Optional[str] = None,\n    ) -> \"Self\":\n        \"\"\"Configure server health check.\n\n        Args:\n        interval: Number of seconds between consecutive health check attempts.\n        rise: Number of consecutive successful health checks required for up.\n        fall: Number of consecutive failed health checks required for DOWN.\n        check_type: Health check type, Can be \"generic\", \"mysql\", \"postgres\", \"redis\" or \"smtp\".\n        send: Only used in generic health checks,\n            specify a string to send in the health check request.\n        expect: Only used in generic health checks,\n            specify the expected response from a health check request.\n        db_user: Only used if type is postgres or mysql,\n            specify the user name to enable HAproxy to send a Client Authentication packet.\n\n        Returns:\n            Self: The HaproxyRouteTcpRequirer class\n        \"\"\"\n        self._application_data[\"check\"] = self._generate_server_health_check_configuration(\n            interval,\n            rise,\n            fall,\n            check_type,\n            send,\n            expect,\n            db_user,\n        )\n        return self\n\n    def configure_rate_limit(\n        self,\n        connections_per_minute: int,\n        policy: TCPRateLimitPolicy = TCPRateLimitPolicy.REJECT,\n    ) -> \"Self\":\n        \"\"\"Configure rate limit.\n\n        Args:\n            connections_per_minute: The number of connections per minute allowed\n            policy: The rate limit policy to apply\n\n        Returns:\n            Self: The HaproxyRouteTcpRequirer class\n        \"\"\"\n        self._application_data[\"rate_limit\"] = self._generate_rate_limit_configuration(\n            connections_per_minute, policy\n        )\n        return self\n\n    def configure_bandwidth_limit(\n        self,\n        upload_bytes_per_second: Optional[int] = None,\n        download_bytes_per_second: Optional[int] = None,\n    ) -> \"Self\":\n        \"\"\"Configure bandwidth limit.\n\n        Args:\n            upload_bytes_per_second: Upload bandwidth limit in bytes per second\n            download_bytes_per_second: Download bandwidth limit in bytes per second\n\n        Returns:\n            Self: The HaproxyRouteTcpRequirer class\n        \"\"\"\n        if not upload_bytes_per_second and not download_bytes_per_second:\n            logger.error(\n                (\n                    \"At least one of `upload_bytes_per_second` \"\n                    \"or `upload_bytes_per_second` must be set.\"\n                )\n            )\n            return self\n        self._application_data[\"bandwidth_limit\"] = {\n            \"download\": download_bytes_per_second,\n            \"upload\": upload_bytes_per_second,\n        }\n\n        return self\n\n    def configure_retry(\n        self,\n        retry_count: int,\n        retry_redispatch: bool = False,\n    ) -> \"Self\":\n        \"\"\"Configure retry.\n\n        Args:\n            retry_count: The number of retries to attempt\n            retry_redispatch: Whether to enable retry redispatch\n\n        Returns:\n            Self: The HaproxyRouteTcpRequirer class\n        \"\"\"\n        self._application_data[\"retry\"] = self._generate_retry_configuration(\n            retry_count, retry_redispatch\n        )\n        return self\n\n    def configure_timeout(\n        self,\n        server_timeout_in_seconds: Optional[int],\n        connect_timeout_in_seconds: Optional[int],\n        queue_timeout_in_seconds: Optional[int],\n    ) -> \"Self\":\n        \"\"\"Configure timeout.\n\n        Args:\n            server_timeout_in_seconds: Server timeout.\n            connect_timeout_in_seconds: Connect timeout.\n            queue_timeout_in_seconds: Queue timeout\n\n        Returns:\n            Self: The HaproxyRouteTcpRequirer class\n        \"\"\"\n        if not (\n            server_timeout_in_seconds or connect_timeout_in_seconds or queue_timeout_in_seconds\n        ):\n            logger.error(\n                (\n                    \"At least one of `server_timeout_in_seconds`, `connect_timeout_in_seconds` \"\n                    \"or `queue_timeout_in_seconds` must be set.\"\n                )\n            )\n            return self\n        self._application_data[\"timeout\"] = self._generate_timeout_configuration(\n            server_timeout_in_seconds, connect_timeout_in_seconds, queue_timeout_in_seconds\n        )\n        return self\n\n    def configure_server_max_connections(self, max_connections: int) -> \"Self\":\n        \"\"\"Set the server max connections.\n\n        Args:\n            max_connections: The number of max connections to set\n\n        Returns:\n            Self: The HaproxyRouteTcpRequirer class\n        \"\"\"\n        self._application_data[\"server_maxconn\"] = max_connections\n        return self\n\n    def disable_tls_termination(self) -> \"Self\":\n        \"\"\"Disable TLS termination.\n\n        Returns:\n            Self: The HaproxyRouteTcpRequirer class\n        \"\"\"\n        self._application_data[\"tls_terminate\"] = False\n        return self\n\n    def allow_http(self) -> \"Self\":\n        \"\"\"Do not enforce TLS.\n\n        Returns:\n            Self: The HaproxyRouteTcpRequirer class\n        \"\"\"\n        self._application_data[\"enforce_tls\"] = False\n        return self\n\n    def configure_deny_list(self, ip_deny_list: Optional[list[IPvAnyAddress]] = None) -> \"Self\":\n        \"\"\"Configure IP deny list.\n\n        Args:\n            ip_deny_list: List of IP addresses to deny\n\n        Returns:\n            Self: The HaproxyRouteTcpRequirer class\n        \"\"\"\n        if not ip_deny_list:\n            ip_deny_list = []\n        self._application_data[\"ip_deny_list\"] = False\n        return self\n"}' --config 'python-packages=pydantic~=2.10'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
+ .model.name = 'jubilant-51e4f0e9'
+ .model.type = 'iaas'
+ .model.controller = 'github-pr-0020d-lxd'
+ .model.cloud = 'localhost'
+ .model.version = '3.6.11'
+ .model.region = 'localhost'
+ .model.model_status.current = 'available'
+ .machines['0'].juju_status.current = 'started'
+ .machines['0'].juju_status.version = '3.6.11'
+ .machines['0'].hostname = 'juju-844308-0'
+ .machines['0'].dns_name = '10.139.41.26'
+ .machines['0'].ip_addresses[0] = '10.139.41.26'
+ .machines['0'].instance_id = 'juju-844308-0'
+ .machines['0'].machine_status.current = 'running'
+ .machines['0'].machine_status.message = 'Running'
+ .machines['0'].modification_status.current = 'applied'
+ .machines['0'].base.name = 'ubuntu'
+ .machines['0'].base.channel = '24.04'
+ .machines['0'].network_interfaces['eth0'].ip_addresses[0] = '10.139.41.26'
+ .machines['0'].network_interfaces['eth0'].mac_address = '00:16:3e:9e:ab:84'
+ .machines['0'].network_interfaces['eth0'].is_up = True
+ .machines['0'].network_interfaces['eth0'].gateway = '10.139.41.1'
+ .machines['0'].network_interfaces['eth0'].space = 'alpha'
+ .machines['0'].constraints = 'arch=amd64'
+ .machines['0'].hardware = 'arch=amd64 cores=0 mem=0M availability-zone=github-runner virt-type=container'
+ .machines['1'].juju_status.current = 'started'
+ .machines['1'].juju_status.version = '3.6.11'
+ .machines['1'].hostname = 'juju-844308-1'
+ .machines['1'].dns_name = '10.139.41.236'
+ .machines['1'].ip_addresses[0] = '10.139.41.236'
+ .machines['1'].instance_id = 'juju-844308-1'
+ .machines['1'].machine_status.current = 'running'
+ .machines['1'].machine_status.message = 'Running'
+ .machines['1'].modification_status.current = 'applied'
+ .machines['1'].base.name = 'ubuntu'
+ .machines['1'].base.channel = '24.04'
+ .machines['1'].network_interfaces['eth0'].ip_addresses[0] = '10.139.41.236'
+ .machines['1'].network_interfaces['eth0'].mac_address = '00:16:3e:4c:e5:c6'
+ .machines['1'].network_interfaces['eth0'].is_up = True
+ .machines['1'].network_interfaces['eth0'].gateway = '10.139.41.1'
+ .machines['1'].network_interfaces['eth0'].space = 'alpha'
+ .machines['1'].constraints = 'arch=amd64'
+ .machines['1'].hardware = 'arch=amd64 cores=0 mem=0M availability-zone=github-runner virt-type=container'
+ .machines['2'].juju_status.current = 'pending'
+ .machines['2'].instance_id = 'pending'
+ .machines['2'].machine_status.current = 'pending'
+ .machines['2'].modification_status.current = 'idle'
+ .machines['2'].base.name = 'ubuntu'
+ .machines['2'].base.channel = '22.04'
+ .machines['2'].constraints = 'arch=amd64'
+ .apps['any-charm-haproxy-route-tcp-requirer'].charm = 'any-charm'
+ .apps['any-charm-haproxy-route-tcp-requirer'].charm_origin = 'charmhub'
+ .apps['any-charm-haproxy-route-tcp-requirer'].charm_name = 'any-charm'
+ .apps['any-charm-haproxy-route-tcp-requirer'].charm_rev = 92
+ .apps['any-charm-haproxy-route-tcp-requirer'].exposed = False
+ .apps['any-charm-haproxy-route-tcp-requirer'].base.name = 'ubuntu'
+ .apps['any-charm-haproxy-route-tcp-requirer'].base.channel = '22.04'
+ .apps['any-charm-haproxy-route-tcp-requirer'].charm_channel = 'latest/beta'
+ .apps['any-charm-haproxy-route-tcp-requirer'].app_status.current = 'waiting'
+ .apps['any-charm-haproxy-route-tcp-requirer'].app_status.message = 'waiting for machine'
+ .apps['any-charm-haproxy-route-tcp-requirer'].relations['peer-any'][0].related_app = 'any-charm-haproxy-route-tcp-requirer'
+ .apps['any-charm-haproxy-route-tcp-requirer'].relations['peer-any'][0].interface = 'peer-any'
+ .apps['any-charm-haproxy-route-tcp-requirer'].relations['peer-any'][0].scope = 'global'
+ .apps['any-charm-haproxy-route-tcp-requirer'].units['any-charm-haproxy-route-tcp-requirer/0'].workload_status.current = 'waiting'
+ .apps['any-charm-haproxy-route-tcp-requirer'].units['any-charm-haproxy-route-tcp-requirer/0'].workload_status.message = 'waiting for machine'
+ .apps['any-charm-haproxy-route-tcp-requirer'].units['any-charm-haproxy-route-tcp-requirer/0'].juju_status.current = 'allocating'
+ .apps['any-charm-haproxy-route-tcp-requirer'].units['any-charm-haproxy-route-tcp-requirer/0'].machine = '2'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings[''] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['dns-record'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['ingress'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['ldap'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['nginx-route'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['peer-any'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-aar'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-agent-auth'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-airbyte-server'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-alertmanager-dispatch'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-alertmanager-remote-configuration'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-anbox-stream-gateway'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-any'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-apache-vhost-config'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-apache-website'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-arangodb'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-auth-proxy'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-autoscaling'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-aws-iam'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-aws-integration'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-azure-integration'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-barbican-hsm'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-barbican-secrets'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-baremetal'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-bgp'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-bind-rndc'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-block-storage'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-cassandra'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-catalogue'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ceilometer'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ceph-admin'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ceph-bootstrap'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ceph-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ceph-dashboard'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ceph-iscsi-admin-access'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ceph-mds'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ceph-osd'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ceph-radosgw'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ceph-rbd-mirror'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-certificate-transfer'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-cinder'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-cinder-backend'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-cinder-backup'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-cinder-ceph-key'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-cinder-gw'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-cinder-nedge'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-cloudflared-route'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-config-server'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-container-runtime'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-containerd'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-containers'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-cos-agent'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-cos-k8s-tokens'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-dashboard'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-dashboard-plugin'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-db'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-db2'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-designate'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-dex-oidc-config'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-dns-record'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-dns-transfer'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-docker-registry'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-dockerhost'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-elastic-beats'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-elasticsearch'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-elasticsearch-datastore'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ephemeral-backend'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-etcd'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-etcd-proxy'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-event-service'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-external-cloud-provider'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-external-provider'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-fiveg-core-gnb'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-fiveg-n2'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-fluentbit'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-forward-auth'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ftn-compiler'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-gcp-integration'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-generic-ip-port-user-pass'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-giraph'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-glance'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-glance-backend'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-glance-simplestreams-sync'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-glauth-auxiliary'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-gnocchi'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-grafana-auth'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-grafana-cloud-config'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-grafana-dashboard'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-grafana-datasource'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-grafana-datasource-exchange'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-grafana-metadata'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-grafana-source'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-guacd'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-hacluster'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-haproxy-route'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-heat-plugin-subordinate'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-http'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-http-proxy'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-httpd'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-hydra-endpoints'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-influxdb-api'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-infoblox'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ingress'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ingress-auth'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ingress-per-unit'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-irc-bridge'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-istio-gateway-info'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-java'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-jenkins-agent-v0'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-jenkins-extension'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-jenkins-slave'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-k8s-cluster'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-k8s-service'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-kafka'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-kafka-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-kapacitor'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-karma-dashboard'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-keystone'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-keystone-admin'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-keystone-credentials'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-keystone-domain-backend'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-keystone-fid-service-provider'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-keystone-middleware'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-keystone-notifications'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-kratos-info'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-kube-control'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-kube-dns'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-kubeflow-dashboard-links'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-kubernetes-cni'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-kubernetes-info'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-landscape-hosted'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ldap'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-livepatch-pro-airgapped-server'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-lldp'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-loadbalancer'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-local-monitors'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-login-ui-endpoints'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-logs'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-logstash-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-loki-push-api'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-lte-core'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-lxd'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-lxd-bgp'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-lxd-dns'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-lxd-https'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-lxd-metrics'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-magma-orchestrator'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-manila-plugin'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-matrix-auth'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-memcache'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-midonet'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-mongodb'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-mongodb-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-monitor'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-monitors'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-mount'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-munin-node'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-mysql'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-mysql-async'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-mysql-async-replication'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-mysql-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-mysql-monitor'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-mysql-root'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-mysql-router'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-mysql-shared'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-nats'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-nedge'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-neutron-api'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-neutron-load-balancer'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-neutron-plugin'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-neutron-plugin-api'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-neutron-plugin-api-subordinate'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-nginx-route'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-nova'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-nova-ceilometer'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-nova-cell'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-nova-compute'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-nova-vgpu'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-nova-vmware'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-nrpe'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-nrpe-external-master'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ntp'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-oathkeeper-info'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-oauth'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-object-storage'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-odl-controller-api'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-oidc-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-openfga'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-opensearch-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-openstack-integration'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-openstack-loadbalancer'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ovsdb'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ovsdb-cluster'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ovsdb-cms'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ovsdb-manager'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ovsdb-subordinate'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-pacemaker-remote'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-parca-scrape'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-parca-store'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-peer-cluster'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-pgsql'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-placement'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-pod-defaults'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-postfix-metrics'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-postgresql-async'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-postgresql-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-prolog-epilog'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-prometheus'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-prometheus-manual'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-prometheus-remote-write'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-prometheus-rules'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-prometheus-scrape'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-public-address'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-quantum'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-rabbitmq'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-radosgw-multisite'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-radosgw-user'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ranger-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-redis'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-register-application'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-rest'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-s3'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-saml'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-script-provider'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-sdcore-config'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-sdn-plugin'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-secrets'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-sentry-metrics'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-service-control'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-service-mesh'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-shards'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-slurmd'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-slurmdbd'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-slurmrestd'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-smtp'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-squid-auth-helper'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ssl-termination'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-statistics'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-stun-server'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-swift'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-swift-global-cluster'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-swift-gw'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-swift-proxy'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-syslog'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-telegraf-exec'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-temporal'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-thruk-agent'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-tls-certificates'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-tokens'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-tracing'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-traefik-route'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-trino-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-ubuntu'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-udldap-userdata'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-untrusted-container-runtime'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-user-group'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-vault-autounseal'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-vault-kv'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-vsd-rest-api'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-vsphere-integration'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-web-publish'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-websso-fid-service-provider'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-websso-trusted-dashboard'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-xlc-compiler'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-zookeeper'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['provide-zuul'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['redis'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-aar'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-agent-auth'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-airbyte-server'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-alertmanager-dispatch'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-alertmanager-remote-configuration'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-anbox-stream-gateway'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-any'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-apache-vhost-config'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-apache-website'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-arangodb'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-auth-proxy'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-autoscaling'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-aws-iam'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-aws-integration'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-azure-integration'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-barbican-hsm'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-barbican-secrets'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-baremetal'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-bgp'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-bind-rndc'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-block-storage'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-cassandra'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-catalogue'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ceilometer'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ceph-admin'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ceph-bootstrap'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ceph-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ceph-dashboard'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ceph-iscsi-admin-access'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ceph-mds'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ceph-osd'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ceph-radosgw'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ceph-rbd-mirror'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-certificate-transfer'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-cinder'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-cinder-backend'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-cinder-backup'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-cinder-ceph-key'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-cinder-gw'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-cinder-nedge'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-cloudflared-route'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-config-server'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-container-runtime'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-containerd'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-containers'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-cos-agent'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-cos-k8s-tokens'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-dashboard'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-dashboard-plugin'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-db'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-db2'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-designate'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-dex-oidc-config'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-dns-record'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-dns-transfer'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-docker-registry'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-dockerhost'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-elastic-beats'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-elasticsearch'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-elasticsearch-datastore'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ephemeral-backend'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-etcd'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-etcd-proxy'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-event-service'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-external-cloud-provider'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-external-provider'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-fiveg-core-gnb'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-fiveg-n2'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-fluentbit'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-forward-auth'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ftn-compiler'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-gcp-integration'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-generic-ip-port-user-pass'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-giraph'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-glance'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-glance-backend'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-glance-simplestreams-sync'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-glauth-auxiliary'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-gnocchi'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-grafana-auth'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-grafana-cloud-config'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-grafana-dashboard'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-grafana-datasource'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-grafana-datasource-exchange'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-grafana-metadata'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-grafana-source'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-guacd'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-hacluster'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-haproxy-route'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-haproxy-route-tcp'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-heat-plugin-subordinate'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-http'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-http-proxy'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-httpd'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-hydra-endpoints'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-influxdb-api'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-infoblox'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ingress'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ingress-auth'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ingress-per-unit'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-irc-bridge'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-istio-gateway-info'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-java'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-jenkins-agent-v0'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-jenkins-extension'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-jenkins-slave'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-k8s-cluster'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-k8s-service'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-kafka'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-kafka-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-kapacitor'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-karma-dashboard'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-keystone'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-keystone-admin'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-keystone-credentials'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-keystone-domain-backend'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-keystone-fid-service-provider'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-keystone-middleware'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-keystone-notifications'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-kratos-info'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-kube-control'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-kube-dns'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-kubeflow-dashboard-links'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-kubernetes-cni'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-kubernetes-info'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-landscape-hosted'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ldap'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-livepatch-pro-airgapped-server'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-lldp'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-loadbalancer'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-local-monitors'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-login-ui-endpoints'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-logs'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-logstash-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-loki-push-api'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-lte-core'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-lxd'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-lxd-bgp'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-lxd-dns'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-lxd-https'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-lxd-metrics'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-magma-orchestrator'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-manila-plugin'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-matrix-auth'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-memcache'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-midonet'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-mongodb'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-mongodb-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-monitor'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-monitors'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-mount'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-munin-node'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-mysql'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-mysql-async'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-mysql-async-replication'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-mysql-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-mysql-monitor'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-mysql-root'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-mysql-router'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-mysql-shared'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-nats'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-nedge'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-neutron-api'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-neutron-load-balancer'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-neutron-plugin'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-neutron-plugin-api'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-neutron-plugin-api-subordinate'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-nginx-route'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-nova'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-nova-ceilometer'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-nova-cell'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-nova-compute'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-nova-vgpu'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-nova-vmware'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-nrpe'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-nrpe-external-master'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ntp'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-oathkeeper-info'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-oauth'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-object-storage'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-odl-controller-api'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-oidc-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-opencti-connector'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-openfga'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-opensearch-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-openstack-integration'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-openstack-loadbalancer'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ovsdb'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ovsdb-cluster'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ovsdb-cms'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ovsdb-manager'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ovsdb-subordinate'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-pacemaker-remote'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-parca-scrape'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-parca-store'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-peer-cluster'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-pgsql'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-placement'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-pod-defaults'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-postfix-metrics'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-postgresql-async'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-postgresql-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-prolog-epilog'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-prometheus'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-prometheus-manual'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-prometheus-remote-write'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-prometheus-rules'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-prometheus-scrape'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-public-address'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-quantum'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-rabbitmq'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-radosgw-multisite'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-radosgw-user'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ranger-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-redis'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-register-application'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-rest'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-s3'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-saml'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-script-provider'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-sdcore-config'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-sdn-plugin'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-secrets'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-sentry-metrics'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-service-control'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-service-mesh'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-shards'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-slurmd'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-slurmdbd'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-slurmrestd'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-smtp'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-squid-auth-helper'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ssl-termination'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-statistics'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-stun-server'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-swift'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-swift-global-cluster'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-swift-gw'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-swift-proxy'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-syslog'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-telegraf-exec'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-temporal'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-thruk-agent'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-tls-certificates'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-tokens'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-tracing'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-traefik-route'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-trino-client'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-ubuntu'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-udldap-userdata'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-untrusted-container-runtime'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-user-group'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-vault-autounseal'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-vault-kv'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-vsd-rest-api'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-vsphere-integration'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-web-publish'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-websso-fid-service-provider'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-websso-trusted-dashboard'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-xlc-compiler'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-zookeeper'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['require-zuul'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['saml'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['send-ca-cert'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['smtp'] = 'alpha'
+ .apps['any-charm-haproxy-route-tcp-requirer'].endpoint_bindings['smtp-legacy'] = 'alpha'
+ .apps['haproxy'].charm = 'local:haproxy-0'
+ .apps['haproxy'].charm_origin = 'local'
+ .apps['haproxy'].charm_name = 'haproxy'
+ .apps['haproxy'].charm_rev = 0
+ .apps['haproxy'].exposed = False
+ .apps['haproxy'].base.name = 'ubuntu'
+ .apps['haproxy'].base.channel = '24.04'
+ .apps['haproxy'].app_status.current = 'active'
+ .apps['haproxy'].relations['certificates'][0].related_app = 'self-signed-certificates'
+ .apps['haproxy'].relations['certificates'][0].interface = 'tls-certificates'
+ .apps['haproxy'].relations['certificates'][0].scope = 'global'
+ .apps['haproxy'].relations['haproxy-peers'][0].related_app = 'haproxy'
+ .apps['haproxy'].relations['haproxy-peers'][0].interface = 'haproxy-peers'
+ .apps['haproxy'].relations['haproxy-peers'][0].scope = 'global'
+ .apps['haproxy'].units['haproxy/0'].workload_status.current = 'active'
+ .apps['haproxy'].units['haproxy/0'].juju_status.current = 'idle'
+ .apps['haproxy'].units['haproxy/0'].juju_status.version = '3.6.11'
+ .apps['haproxy'].units['haproxy/0'].leader = True
+ .apps['haproxy'].units['haproxy/0'].machine = '0'
+ .apps['haproxy'].units['haproxy/0'].open_ports[0] = '80/tcp'
+ .apps['haproxy'].units['haproxy/0'].public_address = '10.139.41.26'
+ .apps['haproxy'].endpoint_bindings[''] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['certificates'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['cos-agent'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['ha'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['haproxy-peers'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['haproxy-route'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['haproxy-route-tcp'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['ingress'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['ingress-per-unit'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['receive-ca-certs'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['reverseproxy'] = 'alpha'
+ .apps['haproxy'].endpoint_bindings['website'] = 'alpha'
+ .apps['self-signed-certificates'].charm = 'self-signed-certificates'
+ .apps['self-signed-certificates'].charm_origin = 'charmhub'
+ .apps['self-signed-certificates'].charm_name = 'self-signed-certificates'
+ .apps['self-signed-certificates'].charm_rev = 416
+ .apps['self-signed-certificates'].exposed = False
+ .apps['self-signed-certificates'].base.name = 'ubuntu'
+ .apps['self-signed-certificates'].base.channel = '24.04'
+ .apps['self-signed-certificates'].charm_channel = '1/edge'
+ .apps['self-signed-certificates'].app_status.current = 'active'
+ .apps['self-signed-certificates'].relations['certificates'][0].related_app = 'haproxy'
+ .apps['self-signed-certificates'].relations['certificates'][0].interface = 'tls-certificates'
+ .apps['self-signed-certificates'].relations['certificates'][0].scope = 'global'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].workload_status.current = 'active'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.current = 'idle'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].juju_status.version = '3.6.11'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].leader = True
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].machine = '1'
+ .apps['self-signed-certificates'].units['self-signed-certificates/0'].public_address = '10.139.41.236'
+ .apps['self-signed-certificates'].endpoint_bindings[''] = 'alpha'
+ .apps['self-signed-certificates'].endpoint_bindings['certificates'] = 'alpha'
+ .apps['self-signed-certificates'].endpoint_bindings['send-ca-cert'] = 'alpha'
+ .apps['self-signed-certificates'].endpoint_bindings['tracing'] = 'alpha'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .machines['2'].machine_status.current = 'pending'
+ .machines['2'].machine_status.current = 'allocating'
+ .machines['2'].machine_status.message = 'acquiring LXD image'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .machines['2'].machine_status.message = 'acquiring LXD image'
+ .machines['2'].machine_status.message = 'Retrieving image: metadata: 100% (1.20GB/s)'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .machines['2'].machine_status.message = 'Retrieving image: metadata: 100% (1.20GB/s)'
+ .machines['2'].machine_status.message = 'Retrieving image: rootfs: 4% (21.25MB/s)'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .machines['2'].machine_status.message = 'Retrieving image: rootfs: 4% (21.25MB/s)'
+ .machines['2'].machine_status.message = 'Retrieving image: rootfs: 19% (43.11MB/s)'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .machines['2'].machine_status.message = 'Retrieving image: rootfs: 19% (43.11MB/s)'
+ .machines['2'].machine_status.message = 'Retrieving image: rootfs: 37% (52.43MB/s)'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .machines['2'].machine_status.message = 'Retrieving image: rootfs: 37% (52.43MB/s)'
+ .machines['2'].machine_status.message = 'Retrieving image: rootfs: 54% (56.48MB/s)'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .machines['2'].machine_status.message = 'Retrieving image: rootfs: 54% (56.48MB/s)'
+ .machines['2'].machine_status.message = 'Retrieving image: rootfs: 69% (57.68MB/s)'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .machines['2'].machine_status.message = 'Retrieving image: rootfs: 69% (57.68MB/s)'
+ .machines['2'].machine_status.message = 'Retrieving image: rootfs: 86% (59.12MB/s)'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .machines['2'].machine_status.message = 'Retrieving image: rootfs: 86% (59.12MB/s)'
+ .machines['2'].machine_status.message = 'Creating container'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
- .machines['2'].instance_id = 'pending'
- .machines['2'].machine_status.current = 'allocating'
- .machines['2'].machine_status.message = 'Creating container'
- .machines['2'].modification_status.current = 'idle'
+ .machines['2'].instance_id = 'juju-844308-2'
+ .machines['2'].machine_status.current = 'running'
+ .machines['2'].machine_status.message = 'Container started'
+ .machines['2'].modification_status.current = 'applied'
+ .machines['2'].hardware = 'arch=amd64 cores=0 mem=0M availability-zone=github-runner virt-type=container'
[32mINFO    [0m jubilant.wait:_juju.py:982 wait: status changed:
+ .machines['2'].dns_name = '10.139.41.226'
+ .machines['2'].ip_addresses[0] = '10.139.41.226'
- .machines['2'].machine_status.message = 'Container started'
+ .machines['2'].machine_status.message = 'Running'
+ .apps['any-charm-haproxy-route-tcp-requirer'].units['any-charm-haproxy-route-tcp-requirer/0'].public_address = '10.139.41.226'