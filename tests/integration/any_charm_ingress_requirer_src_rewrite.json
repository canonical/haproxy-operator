{"ingress.py": "# Copyright 2025 Canonical Ltd.\n# See LICENSE file for licensing details.\n\nr\"\"\"# Interface Library for ingress.\n\nThis library wraps relation endpoints using the `ingress` interface\nand provides a Python API for both requesting and providing per-application\ningress, with load-balancing occurring across all units.\n\n## Getting Started\n\nTo get started using the library, you just need to fetch the library using `charmcraft`.\n\n```shell\ncd some-charm\ncharmcraft fetch-lib charms.traefik_k8s.v2.ingress\n```\n\nIn the `metadata.yaml` of the charm, add the following:\n\n```yaml\nrequires:\n    ingress:\n        interface: ingress\n        limit: 1\n```\n\nThen, to initialise the library:\n\n```python\nfrom charms.traefik_k8s.v2.ingress import (IngressPerAppRequirer,\n  IngressPerAppReadyEvent, IngressPerAppRevokedEvent)\n\nclass SomeCharm(CharmBase):\n  def __init__(self, *args):\n    # ...\n    self.ingress = IngressPerAppRequirer(self, port=80)\n    # The following event is triggered when the ingress URL to be used\n    # by this deployment of the `SomeCharm` is ready (or changes).\n    self.framework.observe(\n        self.ingress.on.ready, self._on_ingress_ready\n    )\n    self.framework.observe(\n        self.ingress.on.revoked, self._on_ingress_revoked\n    )\n\n    def _on_ingress_ready(self, event: IngressPerAppReadyEvent):\n        logger.info(\"This app's ingress URL: %s\", event.url)\n\n    def _on_ingress_revoked(self, event: IngressPerAppRevokedEvent):\n        logger.info(\"This app no longer has ingress\")\n\"\"\"\nimport ipaddress\nimport json\nimport logging\nimport socket\nimport typing\nfrom dataclasses import dataclass\nfrom functools import partial\nfrom typing import Any, Callable, Dict, List, MutableMapping, Optional, Sequence, Tuple, Union\n\nimport pydantic\nfrom ops.charm import CharmBase, RelationBrokenEvent, RelationEvent\nfrom ops.framework import EventSource, Object, ObjectEvents, StoredState\nfrom ops.model import ModelError, Relation, Unit\nfrom pydantic import AnyHttpUrl, BaseModel, Field\n\n# The unique Charmhub library identifier, never change it\nLIBID = \"e6de2a5cd5b34422a204668f3b8f90d2\"\n\n# Increment this major API version when introducing breaking changes\nLIBAPI = 2\n\n# Increment this PATCH version before using `charmcraft publish-lib` or reset\n# to 0 if you are raising the major API version\nLIBPATCH = 14\n\nPYDEPS = [\"pydantic\"]\n\nDEFAULT_RELATION_NAME = \"ingress\"\nRELATION_INTERFACE = \"ingress\"\n\nlog = logging.getLogger(__name__)\nBUILTIN_JUJU_KEYS = {\"ingress-address\", \"private-address\", \"egress-subnets\"}\n\nPYDANTIC_IS_V1 = int(pydantic.version.VERSION.split(\".\")[0]) < 2\nif PYDANTIC_IS_V1:\n    from pydantic import validator\n\n    input_validator = partial(validator, pre=True)\n\n    class DatabagModel(BaseModel):  # type: ignore\n        \"\"\"Base databag model.\"\"\"\n\n        class Config:\n            \"\"\"Pydantic config.\"\"\"\n\n            allow_population_by_field_name = True\n            \"\"\"Allow instantiating this class by field name (instead of forcing alias).\"\"\"\n\n        _NEST_UNDER = None\n\n        @classmethod\n        def load(cls, databag: MutableMapping):\n            \"\"\"Load this model from a Juju databag.\"\"\"\n            if cls._NEST_UNDER:\n                return cls.parse_obj(json.loads(databag[cls._NEST_UNDER]))\n\n            try:\n                data = {\n                    k: json.loads(v)\n                    for k, v in databag.items()\n                    # Don't attempt to parse model-external values\n                    if k in {f.alias for f in cls.__fields__.values()}  # type: ignore\n                }\n            except json.JSONDecodeError as e:\n                msg = f\"invalid databag contents: expecting json. {databag}\"\n                log.error(msg)\n                raise DataValidationError(msg) from e\n\n            try:\n                return cls.parse_raw(json.dumps(data))  # type: ignore\n            except pydantic.ValidationError as e:\n                msg = f\"failed to validate databag: {databag}\"\n                log.debug(msg, exc_info=True)\n                raise DataValidationError(msg) from e\n\n        def dump(self, databag: Optional[MutableMapping] = None, clear: bool = True):\n            \"\"\"Write the contents of this model to Juju databag.\n\n            :param databag: the databag to write the data to.\n            :param clear: ensure the databag is cleared before writing it.\n            \"\"\"\n            if clear and databag:\n                databag.clear()\n\n            if databag is None:\n                databag = {}\n\n            if self._NEST_UNDER:\n                databag[self._NEST_UNDER] = self.json(by_alias=True, exclude_defaults=True)\n                return databag\n\n            for key, value in self.dict(by_alias=True, exclude_defaults=True).items():  # type: ignore\n                databag[key] = json.dumps(value)\n\n            return databag\n\nelse:\n    from pydantic import ConfigDict, field_validator\n\n    input_validator = partial(field_validator, mode=\"before\")\n\n    class DatabagModel(BaseModel):\n        \"\"\"Base databag model.\"\"\"\n\n        model_config = ConfigDict(\n            # tolerate additional keys in databag\n            extra=\"ignore\",\n            # Allow instantiating this class by field name (instead of forcing alias).\n            populate_by_name=True,\n            # Custom config key: whether to nest the whole datastructure (as json)\n            # under a field or spread it out at the toplevel.\n            _NEST_UNDER=None,\n        )  # type: ignore\n        \"\"\"Pydantic config.\"\"\"\n\n        @classmethod\n        def load(cls, databag: MutableMapping):\n            \"\"\"Load this model from a Juju databag.\"\"\"\n            nest_under = cls.model_config.get(\"_NEST_UNDER\")\n            if nest_under:\n                return cls.model_validate(json.loads(databag[nest_under]))  # type: ignore\n\n            try:\n                data = {\n                    k: json.loads(v)\n                    for k, v in databag.items()\n                    # Don't attempt to parse model-external values\n                    if k in {(f.alias or n) for n, f in cls.model_fields.items()}  # type: ignore\n                }\n            except json.JSONDecodeError as e:\n                msg = f\"invalid databag contents: expecting json. {databag}\"\n                log.error(msg)\n                raise DataValidationError(msg) from e\n\n            try:\n                return cls.model_validate_json(json.dumps(data))  # type: ignore\n            except pydantic.ValidationError as e:\n                msg = f\"failed to validate databag: {databag}\"\n                log.debug(msg, exc_info=True)\n                raise DataValidationError(msg) from e\n\n        def dump(self, databag: Optional[MutableMapping] = None, clear: bool = True):\n            \"\"\"Write the contents of this model to Juju databag.\n\n            :param databag: the databag to write the data to.\n            :param clear: ensure the databag is cleared before writing it.\n            \"\"\"\n            if clear and databag:\n                databag.clear()\n\n            if databag is None:\n                databag = {}\n            nest_under = self.model_config.get(\"_NEST_UNDER\")\n            if nest_under:\n                databag[nest_under] = self.model_dump_json(  # type: ignore\n                    by_alias=True,\n                    # skip keys whose values are default\n                    exclude_defaults=True,\n                )\n                return databag\n\n            dct = self.model_dump(mode=\"json\", by_alias=True, exclude_defaults=True)  # type: ignore\n            databag.update({k: json.dumps(v) for k, v in dct.items()})\n            return databag\n\n\n# todo: import these models from charm-relation-interfaces/ingress/v2 instead of redeclaring them\nclass IngressUrl(BaseModel):\n    \"\"\"Ingress url schema.\"\"\"\n\n    url: AnyHttpUrl\n\n\nclass IngressProviderAppData(DatabagModel):\n    \"\"\"Ingress application databag schema.\"\"\"\n\n    ingress: IngressUrl\n\n\nclass ProviderSchema(BaseModel):\n    \"\"\"Provider schema for Ingress.\"\"\"\n\n    app: IngressProviderAppData\n\n\nclass IngressRequirerAppData(DatabagModel):\n    \"\"\"Ingress requirer application databag model.\"\"\"\n\n    model: str = Field(description=\"The model the application is in.\")\n    name: str = Field(description=\"the name of the app requesting ingress.\")\n    port: int = Field(description=\"The port the app wishes to be exposed.\")\n\n    # fields on top of vanilla 'ingress' interface:\n    strip_prefix: Optional[bool] = Field(\n        default=False,\n        description=\"Whether to strip the prefix from the ingress url.\",\n        alias=\"strip-prefix\",\n    )\n    redirect_https: Optional[bool] = Field(\n        default=False,\n        description=\"Whether to redirect http traffic to https.\",\n        alias=\"redirect-https\",\n    )\n\n    scheme: Optional[str] = Field(\n        default=\"http\", description=\"What scheme to use in the generated ingress url\"\n    )\n\n    @input_validator(\"scheme\")\n    def validate_scheme(cls, scheme):  # noqa: N805  # pydantic wants 'cls' as first arg\n        \"\"\"Validate scheme arg.\"\"\"\n        if scheme not in {\"http\", \"https\", \"h2c\"}:\n            raise ValueError(\"invalid scheme: should be one of `http|https|h2c`\")\n        return scheme\n\n    @input_validator(\"port\")\n    def validate_port(cls, port):  # noqa: N805  # pydantic wants 'cls' as first arg\n        \"\"\"Validate port.\"\"\"\n        assert isinstance(port, int), type(port)\n        assert 0 < port < 65535, \"port out of TCP range\"\n        return port\n\n\nclass IngressRequirerUnitData(DatabagModel):\n    \"\"\"Ingress requirer unit databag model.\"\"\"\n\n    host: str = Field(description=\"Hostname at which the unit is reachable.\")\n    ip: Optional[str] = Field(\n        None,\n        description=\"IP at which the unit is reachable, \"\n        \"IP can only be None if the IP information can't be retrieved from juju.\",\n    )\n\n    @input_validator(\"host\")\n    def validate_host(cls, host):  # noqa: N805  # pydantic wants 'cls' as first arg\n        \"\"\"Validate host.\"\"\"\n        assert isinstance(host, str), type(host)\n        return host\n\n    @input_validator(\"ip\")\n    def validate_ip(cls, ip):  # noqa: N805  # pydantic wants 'cls' as first arg\n        \"\"\"Validate ip.\"\"\"\n        if ip is None:\n            return None\n        if not isinstance(ip, str):\n            raise TypeError(f\"got ip of type {type(ip)} instead of expected str\")\n        try:\n            ipaddress.IPv4Address(ip)\n            return ip\n        except ipaddress.AddressValueError:\n            pass\n        try:\n            ipaddress.IPv6Address(ip)\n            return ip\n        except ipaddress.AddressValueError:\n            raise ValueError(f\"{ip!r} is not a valid ip address\")\n\n\nclass RequirerSchema(BaseModel):\n    \"\"\"Requirer schema for Ingress.\"\"\"\n\n    app: IngressRequirerAppData\n    unit: IngressRequirerUnitData\n\n\nclass IngressError(RuntimeError):\n    \"\"\"Base class for custom errors raised by this library.\"\"\"\n\n\nclass NotReadyError(IngressError):\n    \"\"\"Raised when a relation is not ready.\"\"\"\n\n\nclass DataValidationError(IngressError):\n    \"\"\"Raised when data validation fails on IPU relation data.\"\"\"\n\n\nclass _IngressPerAppBase(Object):\n    \"\"\"Base class for IngressPerUnit interface classes.\"\"\"\n\n    def __init__(self, charm: CharmBase, relation_name: str = DEFAULT_RELATION_NAME):\n        super().__init__(charm, relation_name)\n\n        self.charm: CharmBase = charm\n        self.relation_name = relation_name\n        self.app = self.charm.app\n        self.unit = self.charm.unit\n\n        observe = self.framework.observe\n        rel_events = charm.on[relation_name]\n        observe(rel_events.relation_created, self._handle_relation)\n        observe(rel_events.relation_joined, self._handle_relation)\n        observe(rel_events.relation_changed, self._handle_relation)\n        observe(rel_events.relation_departed, self._handle_relation)\n        observe(rel_events.relation_broken, self._handle_relation_broken)\n        observe(charm.on.leader_elected, self._handle_upgrade_or_leader)  # type: ignore\n        observe(charm.on.upgrade_charm, self._handle_upgrade_or_leader)  # type: ignore\n\n    @property\n    def relations(self):\n        \"\"\"The list of Relation instances associated with this endpoint.\"\"\"\n        return list(self.charm.model.relations[self.relation_name])\n\n    def _handle_relation(self, event):\n        \"\"\"Subclasses should implement this method to handle a relation update.\"\"\"\n        pass\n\n    def _handle_relation_broken(self, event):\n        \"\"\"Subclasses should implement this method to handle a relation breaking.\"\"\"\n        pass\n\n    def _handle_upgrade_or_leader(self, event):\n        \"\"\"Subclasses should implement this method to handle upgrades or leadership change.\"\"\"\n        pass\n\n\nclass _IPAEvent(RelationEvent):\n    __args__: Tuple[str, ...] = ()\n    __optional_kwargs__: Dict[str, Any] = {}\n\n    @classmethod\n    def __attrs__(cls):\n        return cls.__args__ + tuple(cls.__optional_kwargs__.keys())\n\n    def __init__(self, handle, relation, *args, **kwargs):\n        super().__init__(handle, relation)\n\n        if not len(self.__args__) == len(args):\n            raise TypeError(\"expected {} args, got {}\".format(len(self.__args__), len(args)))\n\n        for attr, obj in zip(self.__args__, args):\n            setattr(self, attr, obj)\n        for attr, default in self.__optional_kwargs__.items():\n            obj = kwargs.get(attr, default)\n            setattr(self, attr, obj)\n\n    def snapshot(self):\n        dct = super().snapshot()\n        for attr in self.__attrs__():\n            obj = getattr(self, attr)\n            try:\n                dct[attr] = obj\n            except ValueError as e:\n                raise ValueError(\n                    \"cannot automagically serialize {}: \"\n                    \"override this method and do it \"\n                    \"manually.\".format(obj)\n                ) from e\n\n        return dct\n\n    def restore(self, snapshot) -> None:\n        super().restore(snapshot)\n        for attr, obj in snapshot.items():\n            setattr(self, attr, obj)\n\n\nclass IngressPerAppDataProvidedEvent(_IPAEvent):\n    \"\"\"Event representing that ingress data has been provided for an app.\"\"\"\n\n    __args__ = (\"name\", \"model\", \"hosts\", \"strip_prefix\", \"redirect_https\")\n\n    if typing.TYPE_CHECKING:\n        name: Optional[str] = None\n        model: Optional[str] = None\n        # sequence of hostname, port dicts\n        hosts: Sequence[\"IngressRequirerUnitData\"] = ()\n        strip_prefix: bool = False\n        redirect_https: bool = False\n\n\nclass IngressPerAppDataRemovedEvent(RelationEvent):\n    \"\"\"Event representing that ingress data has been removed for an app.\"\"\"\n\n\nclass IngressPerAppProviderEvents(ObjectEvents):\n    \"\"\"Container for IPA Provider events.\"\"\"\n\n    data_provided = EventSource(IngressPerAppDataProvidedEvent)\n    data_removed = EventSource(IngressPerAppDataRemovedEvent)\n\n\n@dataclass\nclass IngressRequirerData:\n    \"\"\"Data exposed by the ingress requirer to the provider.\"\"\"\n\n    app: \"IngressRequirerAppData\"\n    units: List[\"IngressRequirerUnitData\"]\n\n\nclass IngressPerAppProvider(_IngressPerAppBase):\n    \"\"\"Implementation of the provider of ingress.\"\"\"\n\n    on = IngressPerAppProviderEvents()  # type: ignore\n\n    def __init__(\n        self,\n        charm: CharmBase,\n        relation_name: str = DEFAULT_RELATION_NAME,\n    ):\n        \"\"\"Constructor for IngressPerAppProvider.\n\n        Args:\n            charm: The charm that is instantiating the instance.\n            relation_name: The name of the relation endpoint to bind to\n                (defaults to \"ingress\").\n        \"\"\"\n        super().__init__(charm, relation_name)\n\n    def _handle_relation(self, event):\n        # created, joined or changed: if remote side has sent the required data:\n        # notify listeners.\n        if self.is_ready(event.relation):\n            data = self.get_data(event.relation)\n            self.on.data_provided.emit(  # type: ignore\n                event.relation,\n                data.app.name,\n                data.app.model,\n                [\n                    unit.dict() if PYDANTIC_IS_V1 else unit.model_dump(mode=\"json\")\n                    for unit in data.units\n                ],\n                data.app.strip_prefix or False,\n                data.app.redirect_https or False,\n            )\n\n    def _handle_relation_broken(self, event):\n        self.on.data_removed.emit(event.relation)  # type: ignore\n\n    def wipe_ingress_data(self, relation: Relation):\n        \"\"\"Clear ingress data from relation.\"\"\"\n        assert self.unit.is_leader(), \"only leaders can do this\"\n        try:\n            relation.data\n        except ModelError as e:\n            log.warning(\n                \"error {} accessing relation data for {!r}. \"\n                \"Probably a ghost of a dead relation is still \"\n                \"lingering around.\".format(e, relation.name)\n            )\n            return\n        del relation.data[self.app][\"ingress\"]\n\n    def _get_requirer_units_data(self, relation: Relation) -> List[\"IngressRequirerUnitData\"]:\n        \"\"\"Fetch and validate the requirer's app databag.\"\"\"\n        out: List[\"IngressRequirerUnitData\"] = []\n\n        unit: Unit\n        for unit in relation.units:\n            databag = relation.data[unit]\n            try:\n                data = IngressRequirerUnitData.load(databag)\n                out.append(data)\n            except pydantic.ValidationError:\n                log.info(f\"failed to validate remote unit data for {unit}\")\n                raise\n        return out\n\n    @staticmethod\n    def _get_requirer_app_data(relation: Relation) -> \"IngressRequirerAppData\":\n        \"\"\"Fetch and validate the requirer's app databag.\"\"\"\n        app = relation.app\n        if app is None:\n            raise NotReadyError(relation)\n\n        databag = relation.data[app]\n        return IngressRequirerAppData.load(databag)\n\n    def get_data(self, relation: Relation) -> IngressRequirerData:\n        \"\"\"Fetch the remote (requirer) app and units' databags.\"\"\"\n        try:\n            return IngressRequirerData(\n                self._get_requirer_app_data(relation), self._get_requirer_units_data(relation)\n            )\n        except (pydantic.ValidationError, DataValidationError) as e:\n            raise DataValidationError(\"failed to validate ingress requirer data\") from e\n\n    def is_ready(self, relation: Optional[Relation] = None):\n        \"\"\"The Provider is ready if the requirer has sent valid data.\"\"\"\n        if not relation:\n            return any(map(self.is_ready, self.relations))\n\n        try:\n            self.get_data(relation)\n        except (DataValidationError, NotReadyError) as e:\n            log.debug(\"Provider not ready; validation error encountered: %s\" % str(e))\n            return False\n        return True\n\n    def _published_url(self, relation: Relation) -> Optional[\"IngressProviderAppData\"]:\n        \"\"\"Fetch and validate this app databag; return the ingress url.\"\"\"\n        if not self.is_ready(relation) or not self.unit.is_leader():\n            # Handle edge case where remote app name can be missing, e.g.,\n            # relation_broken events.\n            # Also, only leader units can read own app databags.\n            # FIXME https://github.com/canonical/traefik-k8s-operator/issues/34\n            return None\n\n        # fetch the provider's app databag\n        databag = relation.data[self.app]\n        if not databag.get(\"ingress\"):\n            raise NotReadyError(\"This application did not `publish_url` yet.\")\n\n        return IngressProviderAppData.load(databag)\n\n    def publish_url(self, relation: Relation, url: str):\n        \"\"\"Publish to the app databag the ingress url.\"\"\"\n        ingress_url = {\"url\": url}\n        IngressProviderAppData(ingress=ingress_url).dump(relation.data[self.app])  # type: ignore\n\n    @property\n    def proxied_endpoints(self) -> Dict[str, Dict[str, str]]:\n        \"\"\"Returns the ingress settings provided to applications by this IngressPerAppProvider.\n\n        For example, when this IngressPerAppProvider has provided the\n        `http://foo.bar/my-model.my-app` URL to the my-app application, the returned dictionary\n        will be:\n\n        ```\n        {\n            \"my-app\": {\n                \"url\": \"http://foo.bar/my-model.my-app\"\n            }\n        }\n        ```\n        \"\"\"\n        results: Dict[str, Dict[str, str]] = {}\n\n        for ingress_relation in self.relations:\n            if not ingress_relation.app:\n                log.warning(\n                    f\"no app in relation {ingress_relation} when fetching proxied endpoints: skipping\"\n                )\n                continue\n            try:\n                ingress_data = self._published_url(ingress_relation)\n            except NotReadyError:\n                log.warning(\n                    f\"no published url found in {ingress_relation}: \"\n                    f\"traefik didn't publish_url yet to this relation.\"\n                )\n                continue\n\n            if not ingress_data:\n                log.warning(f\"relation {ingress_relation} not ready yet: try again in some time.\")\n                continue\n            if PYDANTIC_IS_V1:\n                results[ingress_relation.app.name] = ingress_data.ingress.dict()\n            else:\n                results[ingress_relation.app.name] = ingress_data.ingress.model_dump(mode=\"json\")\n        return results\n\n\nclass IngressPerAppReadyEvent(_IPAEvent):\n    \"\"\"Event representing that ingress for an app is ready.\"\"\"\n\n    __args__ = (\"url\",)\n    if typing.TYPE_CHECKING:\n        url: Optional[str] = None\n\n\nclass IngressPerAppRevokedEvent(RelationEvent):\n    \"\"\"Event representing that ingress for an app has been revoked.\"\"\"\n\n\nclass IngressPerAppRequirerEvents(ObjectEvents):\n    \"\"\"Container for IPA Requirer events.\"\"\"\n\n    ready = EventSource(IngressPerAppReadyEvent)\n    revoked = EventSource(IngressPerAppRevokedEvent)\n\n\nclass IngressPerAppRequirer(_IngressPerAppBase):\n    \"\"\"Implementation of the requirer of the ingress relation.\"\"\"\n\n    on = IngressPerAppRequirerEvents()  # type: ignore\n\n    # used to prevent spurious urls to be sent out if the event we're currently\n    # handling is a relation-broken one.\n    _stored = StoredState()\n\n    def __init__(\n        self,\n        charm: CharmBase,\n        relation_name: str = DEFAULT_RELATION_NAME,\n        *,\n        host: Optional[str] = None,\n        ip: Optional[str] = None,\n        port: Optional[int] = None,\n        strip_prefix: bool = False,\n        redirect_https: bool = False,\n        # fixme: this is horrible UX.\n        #  shall we switch to manually calling provide_ingress_requirements with all args when ready?\n        scheme: Union[Callable[[], str], str] = lambda: \"http\",\n    ):\n        \"\"\"Constructor for IngressRequirer.\n\n        The request args can be used to specify the ingress properties when the\n        instance is created. If any are set, at least `port` is required, and\n        they will be sent to the ingress provider as soon as it is available.\n        All request args must be given as keyword args.\n\n        Args:\n            charm: the charm that is instantiating the library.\n            relation_name: the name of the relation endpoint to bind to (defaults to `ingress`);\n                relation must be of interface type `ingress` and have \"limit: 1\")\n            host: Hostname to be used by the ingress provider to address the requiring\n                application; if unspecified, the default Kubernetes service name will be used.\n            ip: Alternative addressing method other than host to be used by the ingress provider;\n                if unspecified, binding address from juju network API will be used.\n            strip_prefix: configure Traefik to strip the path prefix.\n            redirect_https: redirect incoming requests to HTTPS.\n            scheme: callable returning the scheme to use when constructing the ingress url.\n                Or a string, if the scheme is known and stable at charm-init-time.\n\n        Request Args:\n            port: the port of the service\n        \"\"\"\n        super().__init__(charm, relation_name)\n        self.charm: CharmBase = charm\n        self.relation_name = relation_name\n        self._strip_prefix = strip_prefix\n        self._redirect_https = redirect_https\n        self._get_scheme = scheme if callable(scheme) else lambda: scheme\n\n        self._stored.set_default(current_url=None)  # type: ignore\n\n        # if instantiated with a port, and we are related, then\n        # we immediately publish our ingress data  to speed up the process.\n        if port:\n            self._auto_data = host, ip, port\n        else:\n            self._auto_data = None\n\n    def _handle_relation(self, event):\n        # created, joined or changed: if we have auto data: publish it\n        self._publish_auto_data()\n        if self.is_ready():\n            # Avoid spurious events, emit only when there is a NEW URL available\n            new_url = (\n                None\n                if isinstance(event, RelationBrokenEvent)\n                else self._get_url_from_relation_data()\n            )\n            if self._stored.current_url != new_url:  # type: ignore\n                self._stored.current_url = new_url  # type: ignore\n                self.on.ready.emit(event.relation, new_url)  # type: ignore\n\n    def _handle_relation_broken(self, event):\n        self._stored.current_url = None  # type: ignore\n        self.on.revoked.emit(event.relation)  # type: ignore\n\n    def _handle_upgrade_or_leader(self, event):\n        \"\"\"On upgrade/leadership change: ensure we publish the data we have.\"\"\"\n        self._publish_auto_data()\n\n    def is_ready(self):\n        \"\"\"The Requirer is ready if the Provider has sent valid data.\"\"\"\n        try:\n            return bool(self._get_url_from_relation_data())\n        except DataValidationError as e:\n            log.debug(\"Requirer not ready; validation error encountered: %s\" % str(e))\n            return False\n\n    def _publish_auto_data(self):\n        if self._auto_data:\n            host, ip, port = self._auto_data\n            self.provide_ingress_requirements(host=host, ip=ip, port=port)\n\n    def provide_ingress_requirements(\n        self,\n        *,\n        scheme: Optional[str] = None,\n        host: Optional[str] = None,\n        ip: Optional[str] = None,\n        port: int,\n    ):\n        \"\"\"Publishes the data that Traefik needs to provide ingress.\n\n        Args:\n            scheme: Scheme to be used; if unspecified, use the one used by __init__.\n            host: Hostname to be used by the ingress provider to address the\n             requirer unit; if unspecified, FQDN will be used instead\n            ip: Alternative addressing method other than host to be used by the ingress provider.\n                if unspecified, binding address from juju network API will be used.\n            port: the port of the service (required)\n        \"\"\"\n        for relation in self.relations:\n            self._provide_ingress_requirements(scheme, host, ip, port, relation)\n\n    def _provide_ingress_requirements(\n        self,\n        scheme: Optional[str],\n        host: Optional[str],\n        ip: Optional[str],\n        port: int,\n        relation: Relation,\n    ):\n        if self.unit.is_leader():\n            self._publish_app_data(scheme, port, relation)\n\n        self._publish_unit_data(host, ip, relation)\n\n    def _publish_unit_data(\n        self,\n        host: Optional[str],\n        ip: Optional[str],\n        relation: Relation,\n    ):\n        if not host:\n            host = socket.getfqdn()\n\n        if ip is None:\n            network_binding = self.charm.model.get_binding(relation)\n            if (\n                network_binding is not None\n                and (bind_address := network_binding.network.bind_address) is not None\n            ):\n                ip = str(bind_address)\n            else:\n                log.error(\"failed to retrieve ip information from juju\")\n\n        unit_databag = relation.data[self.unit]\n        try:\n            IngressRequirerUnitData(host=host, ip=ip).dump(unit_databag)\n        except pydantic.ValidationError as e:\n            msg = \"failed to validate unit data\"\n            log.info(msg, exc_info=True)  # log to INFO because this might be expected\n            raise DataValidationError(msg) from e\n\n    def _publish_app_data(\n        self,\n        scheme: Optional[str],\n        port: int,\n        relation: Relation,\n    ):\n        # assumes leadership!\n        app_databag = relation.data[self.app]\n\n        if not scheme:\n            # If scheme was not provided, use the one given to the constructor.\n            scheme = self._get_scheme()\n\n        try:\n            IngressRequirerAppData(  # type: ignore  # pyright does not like aliases\n                model=self.model.name,\n                name=self.app.name,\n                scheme=scheme,\n                port=port,\n                strip_prefix=self._strip_prefix,  # type: ignore  # pyright does not like aliases\n                redirect_https=self._redirect_https,  # type: ignore  # pyright does not like aliases\n            ).dump(app_databag)\n        except pydantic.ValidationError as e:\n            msg = \"failed to validate app data\"\n            log.info(msg, exc_info=True)  # log to INFO because this might be expected\n            raise DataValidationError(msg) from e\n\n    @property\n    def relation(self):\n        \"\"\"The established Relation instance, or None.\"\"\"\n        return self.relations[0] if self.relations else None\n\n    def _get_url_from_relation_data(self) -> Optional[str]:\n        \"\"\"The full ingress URL to reach the current unit.\n\n        Returns None if the URL isn't available yet.\n        \"\"\"\n        relation = self.relation\n        if not relation or not relation.app:\n            return None\n\n        # fetch the provider's app databag\n        try:\n            databag = relation.data[relation.app]\n        except ModelError as e:\n            log.debug(\n                f\"Error {e} attempting to read remote app data; \"\n                f\"probably we are in a relation_departed hook\"\n            )\n            return None\n\n        if not databag:  # not ready yet\n            return None\n\n        return str(IngressProviderAppData.load(databag).ingress.url)\n\n    @property\n    def url(self) -> Optional[str]:\n        \"\"\"The full ingress URL to reach the current unit.\n\n        Returns None if the URL isn't available yet.\n        \"\"\"\n        data = (\n            typing.cast(Optional[str], self._stored.current_url)  # type: ignore\n            or self._get_url_from_relation_data()\n        )\n        return data\n", "apt.py": "# Copyright 2021 Canonical Ltd.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Abstractions for the system's Debian/Ubuntu package information and repositories.\n\nThis module contains abstractions and wrappers around Debian/Ubuntu-style repositories and\npackages, in order to easily provide an idiomatic and Pythonic mechanism for adding packages and/or\nrepositories to systems for use in machine charms.\n\nA sane default configuration is attainable through nothing more than instantiation of the\nappropriate classes. `DebianPackage` objects provide information about the architecture, version,\nname, and status of a package.\n\n`DebianPackage` will try to look up a package either from `dpkg -L` or from `apt-cache` when\nprovided with a string indicating the package name. If it cannot be located, `PackageNotFoundError`\nwill be returned, as `apt` and `dpkg` otherwise return `100` for all errors, and a meaningful error\nmessage if the package is not known is desirable.\n\nTo install packages with convenience methods:\n\n```python\ntry:\n    # Run `apt-get update`\n    apt.update()\n    apt.add_package(\"zsh\")\n    apt.add_package([\"vim\", \"htop\", \"wget\"])\nexcept PackageNotFoundError:\n    logger.error(\"a specified package not found in package cache or on system\")\nexcept PackageError as e:\n    logger.error(\"could not install package. Reason: %s\", e.message)\n````\n\nTo find details of a specific package:\n\n```python\ntry:\n    vim = apt.DebianPackage.from_system(\"vim\")\n\n    # To find from the apt cache only\n    # apt.DebianPackage.from_apt_cache(\"vim\")\n\n    # To find from installed packages only\n    # apt.DebianPackage.from_installed_package(\"vim\")\n\n    vim.ensure(PackageState.Latest)\n    logger.info(\"updated vim to version: %s\", vim.fullversion)\nexcept PackageNotFoundError:\n    logger.error(\"a specified package not found in package cache or on system\")\nexcept PackageError as e:\n    logger.error(\"could not install package. Reason: %s\", e.message)\n```\n\n\n`RepositoryMapping` will return a dict-like object containing enabled system repositories\nand their properties (available groups, baseuri. gpg key). This class can add, disable, or\nmanipulate repositories. Items can be retrieved as `DebianRepository` objects.\n\nIn order add a new repository with explicit details for fields, a new `DebianRepository` can\nbe added to `RepositoryMapping`\n\n`RepositoryMapping` provides an abstraction around the existing repositories on the system,\nand can be accessed and iterated over like any `Mapping` object, to retrieve values by key,\niterate, or perform other operations.\n\nKeys are constructed as `{repo_type}-{}-{release}` in order to uniquely identify a repository.\n\nRepositories can be added with explicit values through a Python constructor.\n\nExample:\n```python\nrepositories = apt.RepositoryMapping()\n\nif \"deb-example.com-focal\" not in repositories:\n    repositories.add(DebianRepository(enabled=True, repotype=\"deb\",\n                     uri=\"https://example.com\", release=\"focal\", groups=[\"universe\"]))\n```\n\nAlternatively, any valid `sources.list` line may be used to construct a new\n`DebianRepository`.\n\nExample:\n```python\nrepositories = apt.RepositoryMapping()\n\nif \"deb-us.archive.ubuntu.com-xenial\" not in repositories:\n    line = \"deb http://us.archive.ubuntu.com/ubuntu xenial main restricted\"\n    repo = DebianRepository.from_repo_line(line)\n    repositories.add(repo)\n```\n\"\"\"\n\nimport fileinput\nimport glob\nimport logging\nimport os\nimport re\nimport subprocess\nfrom collections.abc import Mapping\nfrom enum import Enum\nfrom subprocess import PIPE, CalledProcessError, check_output\nfrom typing import Iterable, List, Optional, Tuple, Union\nfrom urllib.parse import urlparse\n\nlogger = logging.getLogger(__name__)\n\n# The unique Charmhub library identifier, never change it\nLIBID = \"7c3dbc9c2ad44a47bd6fcb25caa270e5\"\n\n# Increment this major API version when introducing breaking changes\nLIBAPI = 0\n\n# Increment this PATCH version before using `charmcraft publish-lib` or reset\n# to 0 if you are raising the major API version\nLIBPATCH = 14\n\n\nVALID_SOURCE_TYPES = (\"deb\", \"deb-src\")\nOPTIONS_MATCHER = re.compile(r\"\\[.*?\\]\")\n\n\nclass Error(Exception):\n    \"\"\"Base class of most errors raised by this library.\"\"\"\n\n    def __repr__(self):\n        \"\"\"Represent the Error.\"\"\"\n        return \"<{}.{} {}>\".format(type(self).__module__, type(self).__name__, self.args)\n\n    @property\n    def name(self):\n        \"\"\"Return a string representation of the model plus class.\"\"\"\n        return \"<{}.{}>\".format(type(self).__module__, type(self).__name__)\n\n    @property\n    def message(self):\n        \"\"\"Return the message passed as an argument.\"\"\"\n        return self.args[0]\n\n\nclass PackageError(Error):\n    \"\"\"Raised when there's an error installing or removing a package.\"\"\"\n\n\nclass PackageNotFoundError(Error):\n    \"\"\"Raised when a requested package is not known to the system.\"\"\"\n\n\nclass PackageState(Enum):\n    \"\"\"A class to represent possible package states.\"\"\"\n\n    Present = \"present\"\n    Absent = \"absent\"\n    Latest = \"latest\"\n    Available = \"available\"\n\n\nclass DebianPackage:\n    \"\"\"Represents a traditional Debian package and its utility functions.\n\n    `DebianPackage` wraps information and functionality around a known package, whether installed\n    or available. The version, epoch, name, and architecture can be easily queried and compared\n    against other `DebianPackage` objects to determine the latest version or to install a specific\n    version.\n\n    The representation of this object as a string mimics the output from `dpkg` for familiarity.\n\n    Installation and removal of packages is handled through the `state` property or `ensure`\n    method, with the following options:\n\n        apt.PackageState.Absent\n        apt.PackageState.Available\n        apt.PackageState.Present\n        apt.PackageState.Latest\n\n    When `DebianPackage` is initialized, the state of a given `DebianPackage` object will be set to\n    `Available`, `Present`, or `Latest`, with `Absent` implemented as a convenience for removal\n    (though it operates essentially the same as `Available`).\n    \"\"\"\n\n    def __init__(\n        self, name: str, version: str, epoch: str, arch: str, state: PackageState\n    ) -> None:\n        self._name = name\n        self._arch = arch\n        self._state = state\n        self._version = Version(version, epoch)\n\n    def __eq__(self, other) -> bool:\n        \"\"\"Equality for comparison.\n\n        Args:\n          other: a `DebianPackage` object for comparison\n\n        Returns:\n          A boolean reflecting equality\n        \"\"\"\n        return isinstance(other, self.__class__) and (\n            self._name,\n            self._version.number,\n        ) == (other._name, other._version.number)\n\n    def __hash__(self):\n        \"\"\"Return a hash of this package.\"\"\"\n        return hash((self._name, self._version.number))\n\n    def __repr__(self):\n        \"\"\"Represent the package.\"\"\"\n        return \"<{}.{}: {}>\".format(self.__module__, self.__class__.__name__, self.__dict__)\n\n    def __str__(self):\n        \"\"\"Return a human-readable representation of the package.\"\"\"\n        return \"<{}: {}-{}.{} -- {}>\".format(\n            self.__class__.__name__,\n            self._name,\n            self._version,\n            self._arch,\n            str(self._state),\n        )\n\n    @staticmethod\n    def _apt(\n        command: str,\n        package_names: Union[str, List],\n        optargs: Optional[List[str]] = None,\n    ) -> None:\n        \"\"\"Wrap package management commands for Debian/Ubuntu systems.\n\n        Args:\n          command: the command given to `apt-get`\n          package_names: a package name or list of package names to operate on\n          optargs: an (Optional) list of additioanl arguments\n\n        Raises:\n          PackageError if an error is encountered\n        \"\"\"\n        optargs = optargs if optargs is not None else []\n        if isinstance(package_names, str):\n            package_names = [package_names]\n        _cmd = [\"apt-get\", \"-y\", *optargs, command, *package_names]\n        try:\n            env = os.environ.copy()\n            env[\"DEBIAN_FRONTEND\"] = \"noninteractive\"\n            subprocess.run(_cmd, capture_output=True, check=True, text=True, env=env)\n        except CalledProcessError as e:\n            raise PackageError(\n                \"Could not {} package(s) [{}]: {}\".format(command, [*package_names], e.stderr)\n            ) from None\n\n    def _add(self) -> None:\n        \"\"\"Add a package to the system.\"\"\"\n        self._apt(\n            \"install\",\n            \"{}={}\".format(self.name, self.version),\n            optargs=[\"--option=Dpkg::Options::=--force-confold\"],\n        )\n\n    def _remove(self) -> None:\n        \"\"\"Remove a package from the system. Implementation-specific.\"\"\"\n        return self._apt(\"remove\", \"{}={}\".format(self.name, self.version))\n\n    @property\n    def name(self) -> str:\n        \"\"\"Returns the name of the package.\"\"\"\n        return self._name\n\n    def ensure(self, state: PackageState):\n        \"\"\"Ensure that a package is in a given state.\n\n        Args:\n          state: a `PackageState` to reconcile the package to\n\n        Raises:\n          PackageError from the underlying call to apt\n        \"\"\"\n        if self._state is not state:\n            if state not in (PackageState.Present, PackageState.Latest):\n                self._remove()\n            else:\n                self._add()\n        self._state = state\n\n    @property\n    def present(self) -> bool:\n        \"\"\"Returns whether or not a package is present.\"\"\"\n        return self._state in (PackageState.Present, PackageState.Latest)\n\n    @property\n    def latest(self) -> bool:\n        \"\"\"Returns whether the package is the most recent version.\"\"\"\n        return self._state is PackageState.Latest\n\n    @property\n    def state(self) -> PackageState:\n        \"\"\"Returns the current package state.\"\"\"\n        return self._state\n\n    @state.setter\n    def state(self, state: PackageState) -> None:\n        \"\"\"Set the package state to a given value.\n\n        Args:\n          state: a `PackageState` to reconcile the package to\n\n        Raises:\n          PackageError from the underlying call to apt\n        \"\"\"\n        if state in (PackageState.Latest, PackageState.Present):\n            self._add()\n        else:\n            self._remove()\n        self._state = state\n\n    @property\n    def version(self) -> \"Version\":\n        \"\"\"Returns the version for a package.\"\"\"\n        return self._version\n\n    @property\n    def epoch(self) -> str:\n        \"\"\"Returns the epoch for a package. May be unset.\"\"\"\n        return self._version.epoch\n\n    @property\n    def arch(self) -> str:\n        \"\"\"Returns the architecture for a package.\"\"\"\n        return self._arch\n\n    @property\n    def fullversion(self) -> str:\n        \"\"\"Returns the name+epoch for a package.\"\"\"\n        return \"{}.{}\".format(self._version, self._arch)\n\n    @staticmethod\n    def _get_epoch_from_version(version: str) -> Tuple[str, str]:\n        \"\"\"Pull the epoch, if any, out of a version string.\"\"\"\n        epoch_matcher = re.compile(r\"^((?P<epoch>\\d+):)?(?P<version>.*)\")\n        matches = epoch_matcher.search(version).groupdict()\n        return matches.get(\"epoch\", \"\"), matches.get(\"version\")\n\n    @classmethod\n    def from_system(\n        cls, package: str, version: Optional[str] = \"\", arch: Optional[str] = \"\"\n    ) -> \"DebianPackage\":\n        \"\"\"Locates a package, either on the system or known to apt, and serializes the information.\n\n        Args:\n            package: a string representing the package\n            version: an optional string if a specific version is requested\n            arch: an optional architecture, defaulting to `dpkg --print-architecture`. If an\n                architecture is not specified, this will be used for selection.\n\n        \"\"\"\n        try:\n            return DebianPackage.from_installed_package(package, version, arch)\n        except PackageNotFoundError:\n            logger.debug(\n                \"package '%s' is not currently installed or has the wrong architecture.\", package\n            )\n\n        # Ok, try `apt-cache ...`\n        try:\n            return DebianPackage.from_apt_cache(package, version, arch)\n        except (PackageNotFoundError, PackageError):\n            # If we get here, it's not known to the systems.\n            # This seems unnecessary, but virtually all `apt` commands have a return code of `100`,\n            # and providing meaningful error messages without this is ugly.\n            raise PackageNotFoundError(\n                \"Package '{}{}' could not be found on the system or in the apt cache!\".format(\n                    package, \".{}\".format(arch) if arch else \"\"\n                )\n            ) from None\n\n    @classmethod\n    def from_installed_package(\n        cls, package: str, version: Optional[str] = \"\", arch: Optional[str] = \"\"\n    ) -> \"DebianPackage\":\n        \"\"\"Check whether the package is already installed and return an instance.\n\n        Args:\n            package: a string representing the package\n            version: an optional string if a specific version is requested\n            arch: an optional architecture, defaulting to `dpkg --print-architecture`.\n                If an architecture is not specified, this will be used for selection.\n        \"\"\"\n        system_arch = check_output(\n            [\"dpkg\", \"--print-architecture\"], universal_newlines=True\n        ).strip()\n        arch = arch if arch else system_arch\n\n        # Regexps are a really terrible way to do this. Thanks dpkg\n        output = \"\"\n        try:\n            output = check_output([\"dpkg\", \"-l\", package], stderr=PIPE, universal_newlines=True)\n        except CalledProcessError:\n            raise PackageNotFoundError(\"Package is not installed: {}\".format(package)) from None\n\n        # Pop off the output from `dpkg -l' because there's no flag to\n        # omit it`\n        lines = str(output).splitlines()[5:]\n\n        dpkg_matcher = re.compile(\n            r\"\"\"\n        ^(?P<package_status>\\w+?)\\s+\n        (?P<package_name>.*?)(?P<throwaway_arch>:\\w+?)?\\s+\n        (?P<version>.*?)\\s+\n        (?P<arch>\\w+?)\\s+\n        (?P<description>.*)\n        \"\"\",\n            re.VERBOSE,\n        )\n\n        for line in lines:\n            try:\n                matches = dpkg_matcher.search(line).groupdict()\n                package_status = matches[\"package_status\"]\n\n                if not package_status.endswith(\"i\"):\n                    logger.debug(\n                        \"package '%s' in dpkg output but not installed, status: '%s'\",\n                        package,\n                        package_status,\n                    )\n                    break\n\n                epoch, split_version = DebianPackage._get_epoch_from_version(matches[\"version\"])\n                pkg = DebianPackage(\n                    matches[\"package_name\"],\n                    split_version,\n                    epoch,\n                    matches[\"arch\"],\n                    PackageState.Present,\n                )\n                if (pkg.arch == \"all\" or pkg.arch == arch) and (\n                    version == \"\" or str(pkg.version) == version\n                ):\n                    return pkg\n            except AttributeError:\n                logger.warning(\"dpkg matcher could not parse line: %s\", line)\n\n        # If we didn't find it, fail through\n        raise PackageNotFoundError(\"Package {}.{} is not installed!\".format(package, arch))\n\n    @classmethod\n    def from_apt_cache(\n        cls, package: str, version: Optional[str] = \"\", arch: Optional[str] = \"\"\n    ) -> \"DebianPackage\":\n        \"\"\"Check whether the package is already installed and return an instance.\n\n        Args:\n            package: a string representing the package\n            version: an optional string if a specific version is requested\n            arch: an optional architecture, defaulting to `dpkg --print-architecture`.\n                If an architecture is not specified, this will be used for selection.\n        \"\"\"\n        system_arch = check_output(\n            [\"dpkg\", \"--print-architecture\"], universal_newlines=True\n        ).strip()\n        arch = arch if arch else system_arch\n\n        # Regexps are a really terrible way to do this. Thanks dpkg\n        keys = (\"Package\", \"Architecture\", \"Version\")\n\n        try:\n            output = check_output(\n                [\"apt-cache\", \"show\", package], stderr=PIPE, universal_newlines=True\n            )\n        except CalledProcessError as e:\n            raise PackageError(\n                \"Could not list packages in apt-cache: {}\".format(e.stderr)\n            ) from None\n\n        pkg_groups = output.strip().split(\"\\n\\n\")\n        keys = (\"Package\", \"Architecture\", \"Version\")\n\n        for pkg_raw in pkg_groups:\n            lines = str(pkg_raw).splitlines()\n            vals = {}\n            for line in lines:\n                if line.startswith(keys):\n                    items = line.split(\":\", 1)\n                    vals[items[0]] = items[1].strip()\n                else:\n                    continue\n\n            epoch, split_version = DebianPackage._get_epoch_from_version(vals[\"Version\"])\n            pkg = DebianPackage(\n                vals[\"Package\"],\n                split_version,\n                epoch,\n                vals[\"Architecture\"],\n                PackageState.Available,\n            )\n\n            if (pkg.arch == \"all\" or pkg.arch == arch) and (\n                version == \"\" or str(pkg.version) == version\n            ):\n                return pkg\n\n        # If we didn't find it, fail through\n        raise PackageNotFoundError(\"Package {}.{} is not in the apt cache!\".format(package, arch))\n\n\nclass Version:\n    \"\"\"An abstraction around package versions.\n\n    This seems like it should be strictly unnecessary, except that `apt_pkg` is not usable inside a\n    venv, and wedging version comparisons into `DebianPackage` would overcomplicate it.\n\n    This class implements the algorithm found here:\n    https://www.debian.org/doc/debian-policy/ch-controlfields.html#version\n    \"\"\"\n\n    def __init__(self, version: str, epoch: str):\n        self._version = version\n        self._epoch = epoch or \"\"\n\n    def __repr__(self):\n        \"\"\"Represent the package.\"\"\"\n        return \"<{}.{}: {}>\".format(self.__module__, self.__class__.__name__, self.__dict__)\n\n    def __str__(self):\n        \"\"\"Return human-readable representation of the package.\"\"\"\n        return \"{}{}\".format(\"{}:\".format(self._epoch) if self._epoch else \"\", self._version)\n\n    @property\n    def epoch(self):\n        \"\"\"Returns the epoch for a package. May be empty.\"\"\"\n        return self._epoch\n\n    @property\n    def number(self) -> str:\n        \"\"\"Returns the version number for a package.\"\"\"\n        return self._version\n\n    def _get_parts(self, version: str) -> Tuple[str, str]:\n        \"\"\"Separate the version into component upstream and Debian pieces.\"\"\"\n        try:\n            version.rindex(\"-\")\n        except ValueError:\n            # No hyphens means no Debian version\n            return version, \"0\"\n\n        upstream, debian = version.rsplit(\"-\", 1)\n        return upstream, debian\n\n    def _listify(self, revision: str) -> List[str]:\n        \"\"\"Split a revision string into a listself.\n\n        This list is comprised of  alternating between strings and numbers,\n        padded on either end to always be \"str, int, str, int...\" and\n        always be of even length.  This allows us to trivially implement the\n        comparison algorithm described.\n        \"\"\"\n        result = []\n        while revision:\n            rev_1, remains = self._get_alphas(revision)\n            rev_2, remains = self._get_digits(remains)\n            result.extend([rev_1, rev_2])\n            revision = remains\n        return result\n\n    def _get_alphas(self, revision: str) -> Tuple[str, str]:\n        \"\"\"Return a tuple of the first non-digit characters of a revision.\"\"\"\n        # get the index of the first digit\n        for i, char in enumerate(revision):\n            if char.isdigit():\n                if i == 0:\n                    return \"\", revision\n                return revision[0:i], revision[i:]\n        # string is entirely alphas\n        return revision, \"\"\n\n    def _get_digits(self, revision: str) -> Tuple[int, str]:\n        \"\"\"Return a tuple of the first integer characters of a revision.\"\"\"\n        # If the string is empty, return (0,'')\n        if not revision:\n            return 0, \"\"\n        # get the index of the first non-digit\n        for i, char in enumerate(revision):\n            if not char.isdigit():\n                if i == 0:\n                    return 0, revision\n                return int(revision[0:i]), revision[i:]\n        # string is entirely digits\n        return int(revision), \"\"\n\n    def _dstringcmp(self, a, b):  # noqa: C901\n        \"\"\"Debian package version string section lexical sort algorithm.\n\n        The lexical comparison is a comparison of ASCII values modified so\n        that all the letters sort earlier than all the non-letters and so that\n        a tilde sorts before anything, even the end of a part.\n        \"\"\"\n        if a == b:\n            return 0\n        try:\n            for i, char in enumerate(a):\n                if char == b[i]:\n                    continue\n                # \"a tilde sorts before anything, even the end of a part\"\n                # (emptyness)\n                if char == \"~\":\n                    return -1\n                if b[i] == \"~\":\n                    return 1\n                # \"all the letters sort earlier than all the non-letters\"\n                if char.isalpha() and not b[i].isalpha():\n                    return -1\n                if not char.isalpha() and b[i].isalpha():\n                    return 1\n                # otherwise lexical sort\n                if ord(char) > ord(b[i]):\n                    return 1\n                if ord(char) < ord(b[i]):\n                    return -1\n        except IndexError:\n            # a is longer than b but otherwise equal, greater unless there are tildes\n            if char == \"~\":\n                return -1\n            return 1\n        # if we get here, a is shorter than b but otherwise equal, so check for tildes...\n        if b[len(a)] == \"~\":\n            return 1\n        return -1\n\n    def _compare_revision_strings(self, first: str, second: str):  # noqa: C901\n        \"\"\"Compare two debian revision strings.\"\"\"\n        if first == second:\n            return 0\n\n        # listify pads results so that we will always be comparing ints to ints\n        # and strings to strings (at least until we fall off the end of a list)\n        first_list = self._listify(first)\n        second_list = self._listify(second)\n        if first_list == second_list:\n            return 0\n        try:\n            for i, item in enumerate(first_list):\n                # explicitly raise IndexError if we've fallen off the edge of list2\n                if i >= len(second_list):\n                    raise IndexError\n                # if the items are equal, next\n                if item == second_list[i]:\n                    continue\n                # numeric comparison\n                if isinstance(item, int):\n                    if item > second_list[i]:\n                        return 1\n                    if item < second_list[i]:\n                        return -1\n                else:\n                    # string comparison\n                    return self._dstringcmp(item, second_list[i])\n        except IndexError:\n            # rev1 is longer than rev2 but otherwise equal, hence greater\n            # ...except for goddamn tildes\n            if first_list[len(second_list)][0][0] == \"~\":\n                return 1\n            return 1\n        # rev1 is shorter than rev2 but otherwise equal, hence lesser\n        # ...except for goddamn tildes\n        if second_list[len(first_list)][0][0] == \"~\":\n            return -1\n        return -1\n\n    def _compare_version(self, other) -> int:\n        if (self.number, self.epoch) == (other.number, other.epoch):\n            return 0\n\n        if self.epoch < other.epoch:\n            return -1\n        if self.epoch > other.epoch:\n            return 1\n\n        # If none of these are true, follow the algorithm\n        upstream_version, debian_version = self._get_parts(self.number)\n        other_upstream_version, other_debian_version = self._get_parts(other.number)\n\n        upstream_cmp = self._compare_revision_strings(upstream_version, other_upstream_version)\n        if upstream_cmp != 0:\n            return upstream_cmp\n\n        debian_cmp = self._compare_revision_strings(debian_version, other_debian_version)\n        if debian_cmp != 0:\n            return debian_cmp\n\n        return 0\n\n    def __lt__(self, other) -> bool:\n        \"\"\"Less than magic method impl.\"\"\"\n        return self._compare_version(other) < 0\n\n    def __eq__(self, other) -> bool:\n        \"\"\"Equality magic method impl.\"\"\"\n        return self._compare_version(other) == 0\n\n    def __gt__(self, other) -> bool:\n        \"\"\"Greater than magic method impl.\"\"\"\n        return self._compare_version(other) > 0\n\n    def __le__(self, other) -> bool:\n        \"\"\"Less than or equal to magic method impl.\"\"\"\n        return self.__eq__(other) or self.__lt__(other)\n\n    def __ge__(self, other) -> bool:\n        \"\"\"Greater than or equal to magic method impl.\"\"\"\n        return self.__gt__(other) or self.__eq__(other)\n\n    def __ne__(self, other) -> bool:\n        \"\"\"Not equal to magic method impl.\"\"\"\n        return not self.__eq__(other)\n\n\ndef add_package(\n    package_names: Union[str, List[str]],\n    version: Optional[str] = \"\",\n    arch: Optional[str] = \"\",\n    update_cache: Optional[bool] = False,\n) -> Union[DebianPackage, List[DebianPackage]]:\n    \"\"\"Add a package or list of packages to the system.\n\n    Args:\n        package_names: single package name, or list of package names\n        name: the name(s) of the package(s)\n        version: an (Optional) version as a string. Defaults to the latest known\n        arch: an optional architecture for the package\n        update_cache: whether or not to run `apt-get update` prior to operating\n\n    Raises:\n        TypeError if no package name is given, or explicit version is set for multiple packages\n        PackageNotFoundError if the package is not in the cache.\n        PackageError if packages fail to install\n    \"\"\"\n    cache_refreshed = False\n    if update_cache:\n        update()\n        cache_refreshed = True\n\n    packages = {\"success\": [], \"retry\": [], \"failed\": []}\n\n    package_names = [package_names] if isinstance(package_names, str) else package_names\n    if not package_names:\n        raise TypeError(\"Expected at least one package name to add, received zero!\")\n\n    if len(package_names) != 1 and version:\n        raise TypeError(\n            \"Explicit version should not be set if more than one package is being added!\"\n        )\n\n    for p in package_names:\n        pkg, success = _add(p, version, arch)\n        if success:\n            packages[\"success\"].append(pkg)\n        else:\n            logger.warning(\"failed to locate and install/update '%s'\", pkg)\n            packages[\"retry\"].append(p)\n\n    if packages[\"retry\"] and not cache_refreshed:\n        logger.info(\"updating the apt-cache and retrying installation of failed packages.\")\n        update()\n\n        for p in packages[\"retry\"]:\n            pkg, success = _add(p, version, arch)\n            if success:\n                packages[\"success\"].append(pkg)\n            else:\n                packages[\"failed\"].append(p)\n\n    if packages[\"failed\"]:\n        raise PackageError(\"Failed to install packages: {}\".format(\", \".join(packages[\"failed\"])))\n\n    return packages[\"success\"] if len(packages[\"success\"]) > 1 else packages[\"success\"][0]\n\n\ndef _add(\n    name: str,\n    version: Optional[str] = \"\",\n    arch: Optional[str] = \"\",\n) -> Tuple[Union[DebianPackage, str], bool]:\n    \"\"\"Add a package to the system.\n\n    Args:\n        name: the name(s) of the package(s)\n        version: an (Optional) version as a string. Defaults to the latest known\n        arch: an optional architecture for the package\n\n    Returns: a tuple of `DebianPackage` if found, or a :str: if it is not, and\n        a boolean indicating success\n    \"\"\"\n    try:\n        pkg = DebianPackage.from_system(name, version, arch)\n        pkg.ensure(state=PackageState.Present)\n        return pkg, True\n    except PackageNotFoundError:\n        return name, False\n\n\ndef remove_package(\n    package_names: Union[str, List[str]]\n) -> Union[DebianPackage, List[DebianPackage]]:\n    \"\"\"Remove package(s) from the system.\n\n    Args:\n        package_names: the name of a package\n\n    Raises:\n        PackageNotFoundError if the package is not found.\n    \"\"\"\n    packages = []\n\n    package_names = [package_names] if isinstance(package_names, str) else package_names\n    if not package_names:\n        raise TypeError(\"Expected at least one package name to add, received zero!\")\n\n    for p in package_names:\n        try:\n            pkg = DebianPackage.from_installed_package(p)\n            pkg.ensure(state=PackageState.Absent)\n            packages.append(pkg)\n        except PackageNotFoundError:\n            logger.info(\"package '%s' was requested for removal, but it was not installed.\", p)\n\n    # the list of packages will be empty when no package is removed\n    logger.debug(\"packages: '%s'\", packages)\n    return packages[0] if len(packages) == 1 else packages\n\n\ndef update() -> None:\n    \"\"\"Update the apt cache via `apt-get update`.\"\"\"\n    subprocess.run([\"apt-get\", \"update\", \"--error-on=any\"], capture_output=True, check=True)\n\n\ndef import_key(key: str) -> str:\n    \"\"\"Import an ASCII Armor key.\n\n    A Radix64 format keyid is also supported for backwards\n    compatibility. In this case Ubuntu keyserver will be\n    queried for a key via HTTPS by its keyid. This method\n    is less preferable because https proxy servers may\n    require traffic decryption which is equivalent to a\n    man-in-the-middle attack (a proxy server impersonates\n    keyserver TLS certificates and has to be explicitly\n    trusted by the system).\n\n    Args:\n        key: A GPG key in ASCII armor format, including BEGIN\n            and END markers or a keyid.\n\n    Returns:\n        The GPG key filename written.\n\n    Raises:\n        GPGKeyError if the key could not be imported\n    \"\"\"\n    key = key.strip()\n    if \"-\" in key or \"\\n\" in key:\n        # Send everything not obviously a keyid to GPG to import, as\n        # we trust its validation better than our own. eg. handling\n        # comments before the key.\n        logger.debug(\"PGP key found (looks like ASCII Armor format)\")\n        if (\n            \"-----BEGIN PGP PUBLIC KEY BLOCK-----\" in key\n            and \"-----END PGP PUBLIC KEY BLOCK-----\" in key\n        ):\n            logger.debug(\"Writing provided PGP key in the binary format\")\n            key_bytes = key.encode(\"utf-8\")\n            key_name = DebianRepository._get_keyid_by_gpg_key(key_bytes)\n            key_gpg = DebianRepository._dearmor_gpg_key(key_bytes)\n            gpg_key_filename = \"/etc/apt/trusted.gpg.d/{}.gpg\".format(key_name)\n            DebianRepository._write_apt_gpg_keyfile(\n                key_name=gpg_key_filename, key_material=key_gpg\n            )\n            return gpg_key_filename\n        else:\n            raise GPGKeyError(\"ASCII armor markers missing from GPG key\")\n    else:\n        logger.warning(\n            \"PGP key found (looks like Radix64 format). \"\n            \"SECURELY importing PGP key from keyserver; \"\n            \"full key not provided.\"\n        )\n        # as of bionic add-apt-repository uses curl with an HTTPS keyserver URL\n        # to retrieve GPG keys. `apt-key adv` command is deprecated as is\n        # apt-key in general as noted in its manpage. See lp:1433761 for more\n        # history. Instead, /etc/apt/trusted.gpg.d is used directly to drop\n        # gpg\n        key_asc = DebianRepository._get_key_by_keyid(key)\n        # write the key in GPG format so that apt-key list shows it\n        key_gpg = DebianRepository._dearmor_gpg_key(key_asc.encode(\"utf-8\"))\n        gpg_key_filename = \"/etc/apt/trusted.gpg.d/{}.gpg\".format(key)\n        DebianRepository._write_apt_gpg_keyfile(key_name=gpg_key_filename, key_material=key_gpg)\n        return gpg_key_filename\n\n\nclass InvalidSourceError(Error):\n    \"\"\"Exceptions for invalid source entries.\"\"\"\n\n\nclass GPGKeyError(Error):\n    \"\"\"Exceptions for GPG keys.\"\"\"\n\n\nclass DebianRepository:\n    \"\"\"An abstraction to represent a repository.\"\"\"\n\n    def __init__(\n        self,\n        enabled: bool,\n        repotype: str,\n        uri: str,\n        release: str,\n        groups: List[str],\n        filename: Optional[str] = \"\",\n        gpg_key_filename: Optional[str] = \"\",\n        options: Optional[dict] = None,\n    ):\n        self._enabled = enabled\n        self._repotype = repotype\n        self._uri = uri\n        self._release = release\n        self._groups = groups\n        self._filename = filename\n        self._gpg_key_filename = gpg_key_filename\n        self._options = options\n\n    @property\n    def enabled(self):\n        \"\"\"Return whether or not the repository is enabled.\"\"\"\n        return self._enabled\n\n    @property\n    def repotype(self):\n        \"\"\"Return whether it is binary or source.\"\"\"\n        return self._repotype\n\n    @property\n    def uri(self):\n        \"\"\"Return the URI.\"\"\"\n        return self._uri\n\n    @property\n    def release(self):\n        \"\"\"Return which Debian/Ubuntu releases it is valid for.\"\"\"\n        return self._release\n\n    @property\n    def groups(self):\n        \"\"\"Return the enabled package groups.\"\"\"\n        return self._groups\n\n    @property\n    def filename(self):\n        \"\"\"Returns the filename for a repository.\"\"\"\n        return self._filename\n\n    @filename.setter\n    def filename(self, fname: str) -> None:\n        \"\"\"Set the filename used when a repo is written back to disk.\n\n        Args:\n            fname: a filename to write the repository information to.\n        \"\"\"\n        if not fname.endswith(\".list\"):\n            raise InvalidSourceError(\"apt source filenames should end in .list!\")\n\n        self._filename = fname\n\n    @property\n    def gpg_key(self):\n        \"\"\"Returns the path to the GPG key for this repository.\"\"\"\n        return self._gpg_key_filename\n\n    @property\n    def options(self):\n        \"\"\"Returns any additional repo options which are set.\"\"\"\n        return self._options\n\n    def make_options_string(self) -> str:\n        \"\"\"Generate the complete options string for a a repository.\n\n        Combining `gpg_key`, if set, and the rest of the options to find\n        a complex repo string.\n        \"\"\"\n        options = self._options if self._options else {}\n        if self._gpg_key_filename:\n            options[\"signed-by\"] = self._gpg_key_filename\n\n        return (\n            \"[{}] \".format(\" \".join([\"{}={}\".format(k, v) for k, v in options.items()]))\n            if options\n            else \"\"\n        )\n\n    @staticmethod\n    def prefix_from_uri(uri: str) -> str:\n        \"\"\"Get a repo list prefix from the uri, depending on whether a path is set.\"\"\"\n        uridetails = urlparse(uri)\n        path = (\n            uridetails.path.lstrip(\"/\").replace(\"/\", \"-\") if uridetails.path else uridetails.netloc\n        )\n        return \"/etc/apt/sources.list.d/{}\".format(path)\n\n    @staticmethod\n    def from_repo_line(repo_line: str, write_file: Optional[bool] = True) -> \"DebianRepository\":\n        \"\"\"Instantiate a new `DebianRepository` a `sources.list` entry line.\n\n        Args:\n            repo_line: a string representing a repository entry\n            write_file: boolean to enable writing the new repo to disk\n        \"\"\"\n        repo = RepositoryMapping._parse(repo_line, \"UserInput\")\n        fname = \"{}-{}.list\".format(\n            DebianRepository.prefix_from_uri(repo.uri), repo.release.replace(\"/\", \"-\")\n        )\n        repo.filename = fname\n\n        options = repo.options if repo.options else {}\n        if repo.gpg_key:\n            options[\"signed-by\"] = repo.gpg_key\n\n        # For Python 3.5 it's required to use sorted in the options dict in order to not have\n        # different results in the order of the options between executions.\n        options_str = (\n            \"[{}] \".format(\" \".join([\"{}={}\".format(k, v) for k, v in sorted(options.items())]))\n            if options\n            else \"\"\n        )\n\n        if write_file:\n            with open(fname, \"wb\") as f:\n                f.write(\n                    (\n                        \"{}\".format(\"#\" if not repo.enabled else \"\")\n                        + \"{} {}{} \".format(repo.repotype, options_str, repo.uri)\n                        + \"{} {}\\n\".format(repo.release, \" \".join(repo.groups))\n                    ).encode(\"utf-8\")\n                )\n\n        return repo\n\n    def disable(self) -> None:\n        \"\"\"Remove this repository from consideration.\n\n        Disable it instead of removing from the repository file.\n        \"\"\"\n        searcher = \"{} {}{} {}\".format(\n            self.repotype, self.make_options_string(), self.uri, self.release\n        )\n        for line in fileinput.input(self._filename, inplace=True):\n            if re.match(r\"^{}\\s\".format(re.escape(searcher)), line):\n                print(\"# {}\".format(line), end=\"\")\n            else:\n                print(line, end=\"\")\n\n    def import_key(self, key: str) -> None:\n        \"\"\"Import an ASCII Armor key.\n\n        A Radix64 format keyid is also supported for backwards\n        compatibility. In this case Ubuntu keyserver will be\n        queried for a key via HTTPS by its keyid. This method\n        is less preferable because https proxy servers may\n        require traffic decryption which is equivalent to a\n        man-in-the-middle attack (a proxy server impersonates\n        keyserver TLS certificates and has to be explicitly\n        trusted by the system).\n\n        Args:\n          key: A GPG key in ASCII armor format,\n                      including BEGIN and END markers or a keyid.\n\n        Raises:\n          GPGKeyError if the key could not be imported\n        \"\"\"\n        self._gpg_key_filename = import_key(key)\n\n    @staticmethod\n    def _get_keyid_by_gpg_key(key_material: bytes) -> str:\n        \"\"\"Get a GPG key fingerprint by GPG key material.\n\n        Gets a GPG key fingerprint (40-digit, 160-bit) by the ASCII armor-encoded\n        or binary GPG key material. Can be used, for example, to generate file\n        names for keys passed via charm options.\n        \"\"\"\n        # Use the same gpg command for both Xenial and Bionic\n        cmd = [\"gpg\", \"--with-colons\", \"--with-fingerprint\"]\n        ps = subprocess.run(\n            cmd,\n            stdout=PIPE,\n            stderr=PIPE,\n            input=key_material,\n        )\n        out, err = ps.stdout.decode(), ps.stderr.decode()\n        if \"gpg: no valid OpenPGP data found.\" in err:\n            raise GPGKeyError(\"Invalid GPG key material provided\")\n        # from gnupg2 docs: fpr :: Fingerprint (fingerprint is in field 10)\n        return re.search(r\"^fpr:{9}([0-9A-F]{40}):$\", out, re.MULTILINE).group(1)\n\n    @staticmethod\n    def _get_key_by_keyid(keyid: str) -> str:\n        \"\"\"Get a key via HTTPS from the Ubuntu keyserver.\n\n        Different key ID formats are supported by SKS keyservers (the longer ones\n        are more secure, see \"dead beef attack\" and https://evil32.com/). Since\n        HTTPS is used, if SSLBump-like HTTPS proxies are in place, they will\n        impersonate keyserver.ubuntu.com and generate a certificate with\n        keyserver.ubuntu.com in the CN field or in SubjAltName fields of a\n        certificate. If such proxy behavior is expected it is necessary to add the\n        CA certificate chain containing the intermediate CA of the SSLBump proxy to\n        every machine that this code runs on via ca-certs cloud-init directive (via\n        cloudinit-userdata model-config) or via other means (such as through a\n        custom charm option). Also note that DNS resolution for the hostname in a\n        URL is done at a proxy server - not at the client side.\n        8-digit (32 bit) key ID\n        https://keyserver.ubuntu.com/pks/lookup?search=0x4652B4E6\n        16-digit (64 bit) key ID\n        https://keyserver.ubuntu.com/pks/lookup?search=0x6E85A86E4652B4E6\n        40-digit key ID:\n        https://keyserver.ubuntu.com/pks/lookup?search=0x35F77D63B5CEC106C577ED856E85A86E4652B4E6\n\n        Args:\n          keyid: An 8, 16 or 40 hex digit keyid to find a key for\n\n        Returns:\n          A string contining key material for the specified GPG key id\n\n\n        Raises:\n          subprocess.CalledProcessError\n        \"\"\"\n        # options=mr - machine-readable output (disables html wrappers)\n        keyserver_url = (\n            \"https://keyserver.ubuntu.com\" \"/pks/lookup?op=get&options=mr&exact=on&search=0x{}\"\n        )\n        curl_cmd = [\"curl\", keyserver_url.format(keyid)]\n        # use proxy server settings in order to retrieve the key\n        return check_output(curl_cmd).decode()\n\n    @staticmethod\n    def _dearmor_gpg_key(key_asc: bytes) -> bytes:\n        \"\"\"Convert a GPG key in the ASCII armor format to the binary format.\n\n        Args:\n          key_asc: A GPG key in ASCII armor format.\n\n        Returns:\n          A GPG key in binary format as a string\n\n        Raises:\n          GPGKeyError\n        \"\"\"\n        ps = subprocess.run([\"gpg\", \"--dearmor\"], stdout=PIPE, stderr=PIPE, input=key_asc)\n        out, err = ps.stdout, ps.stderr.decode()\n        if \"gpg: no valid OpenPGP data found.\" in err:\n            raise GPGKeyError(\n                \"Invalid GPG key material. Check your network setup\"\n                \" (MTU, routing, DNS) and/or proxy server settings\"\n                \" as well as destination keyserver status.\"\n            )\n        else:\n            return out\n\n    @staticmethod\n    def _write_apt_gpg_keyfile(key_name: str, key_material: bytes) -> None:\n        \"\"\"Write GPG key material into a file at a provided path.\n\n        Args:\n          key_name: A key name to use for a key file (could be a fingerprint)\n          key_material: A GPG key material (binary)\n        \"\"\"\n        with open(key_name, \"wb\") as keyf:\n            keyf.write(key_material)\n\n\nclass RepositoryMapping(Mapping):\n    \"\"\"An representation of known repositories.\n\n    Instantiation of `RepositoryMapping` will iterate through the\n    filesystem, parse out repository files in `/etc/apt/...`, and create\n    `DebianRepository` objects in this list.\n\n    Typical usage:\n\n        repositories = apt.RepositoryMapping()\n        repositories.add(DebianRepository(\n            enabled=True, repotype=\"deb\", uri=\"https://example.com\", release=\"focal\",\n            groups=[\"universe\"]\n        ))\n    \"\"\"\n\n    def __init__(self):\n        self._repository_map = {}\n        # Repositories that we're adding -- used to implement mode param\n        self.default_file = \"/etc/apt/sources.list\"\n\n        # read sources.list if it exists\n        if os.path.isfile(self.default_file):\n            self.load(self.default_file)\n\n        # read sources.list.d\n        for file in glob.iglob(\"/etc/apt/sources.list.d/*.list\"):\n            self.load(file)\n\n    def __contains__(self, key: str) -> bool:\n        \"\"\"Magic method for checking presence of repo in mapping.\"\"\"\n        return key in self._repository_map\n\n    def __len__(self) -> int:\n        \"\"\"Return number of repositories in map.\"\"\"\n        return len(self._repository_map)\n\n    def __iter__(self) -> Iterable[DebianRepository]:\n        \"\"\"Return iterator for RepositoryMapping.\"\"\"\n        return iter(self._repository_map.values())\n\n    def __getitem__(self, repository_uri: str) -> DebianRepository:\n        \"\"\"Return a given `DebianRepository`.\"\"\"\n        return self._repository_map[repository_uri]\n\n    def __setitem__(self, repository_uri: str, repository: DebianRepository) -> None:\n        \"\"\"Add a `DebianRepository` to the cache.\"\"\"\n        self._repository_map[repository_uri] = repository\n\n    def load(self, filename: str):\n        \"\"\"Load a repository source file into the cache.\n\n        Args:\n          filename: the path to the repository file\n        \"\"\"\n        parsed = []\n        skipped = []\n        with open(filename, \"r\") as f:\n            for n, line in enumerate(f):\n                try:\n                    repo = self._parse(line, filename)\n                except InvalidSourceError:\n                    skipped.append(n)\n                else:\n                    repo_identifier = \"{}-{}-{}\".format(repo.repotype, repo.uri, repo.release)\n                    self._repository_map[repo_identifier] = repo\n                    parsed.append(n)\n                    logger.debug(\"parsed repo: '%s'\", repo_identifier)\n\n        if skipped:\n            skip_list = \", \".join(str(s) for s in skipped)\n            logger.debug(\"skipped the following lines in file '%s': %s\", filename, skip_list)\n\n        if parsed:\n            logger.info(\"parsed %d apt package repositories\", len(parsed))\n        else:\n            raise InvalidSourceError(\"all repository lines in '{}' were invalid!\".format(filename))\n\n    @staticmethod\n    def _parse(line: str, filename: str) -> DebianRepository:\n        \"\"\"Parse a line in a sources.list file.\n\n        Args:\n          line: a single line from `load` to parse\n          filename: the filename being read\n\n        Raises:\n          InvalidSourceError if the source type is unknown\n        \"\"\"\n        enabled = True\n        repotype = uri = release = gpg_key = \"\"\n        options = {}\n        groups = []\n\n        line = line.strip()\n        if line.startswith(\"#\"):\n            enabled = False\n            line = line[1:]\n\n        # Check for \"#\" in the line and treat a part after it as a comment then strip it off.\n        i = line.find(\"#\")\n        if i > 0:\n            line = line[:i]\n\n        # Split a source into substrings to initialize a new repo.\n        source = line.strip()\n        if source:\n            # Match any repo options, and get a dict representation.\n            for v in re.findall(OPTIONS_MATCHER, source):\n                opts = dict(o.split(\"=\") for o in v.strip(\"[]\").split())\n                # Extract the 'signed-by' option for the gpg_key\n                gpg_key = opts.pop(\"signed-by\", \"\")\n                options = opts\n\n            # Remove any options from the source string and split the string into chunks\n            source = re.sub(OPTIONS_MATCHER, \"\", source)\n            chunks = source.split()\n\n            # Check we've got a valid list of chunks\n            if len(chunks) < 3 or chunks[0] not in VALID_SOURCE_TYPES:\n                raise InvalidSourceError(\"An invalid sources line was found in %s!\", filename)\n\n            repotype = chunks[0]\n            uri = chunks[1]\n            release = chunks[2]\n            groups = chunks[3:]\n\n            return DebianRepository(\n                enabled, repotype, uri, release, groups, filename, gpg_key, options\n            )\n        else:\n            raise InvalidSourceError(\"An invalid sources line was found in %s!\", filename)\n\n    def add(self, repo: DebianRepository, default_filename: Optional[bool] = False) -> None:\n        \"\"\"Add a new repository to the system.\n\n        Args:\n          repo: a `DebianRepository` object\n          default_filename: an (Optional) filename if the default is not desirable\n        \"\"\"\n        new_filename = \"{}-{}.list\".format(\n            DebianRepository.prefix_from_uri(repo.uri), repo.release.replace(\"/\", \"-\")\n        )\n\n        fname = repo.filename or new_filename\n\n        options = repo.options if repo.options else {}\n        if repo.gpg_key:\n            options[\"signed-by\"] = repo.gpg_key\n\n        with open(fname, \"wb\") as f:\n            f.write(\n                (\n                    \"{}\".format(\"#\" if not repo.enabled else \"\")\n                    + \"{} {}{} \".format(repo.repotype, repo.make_options_string(), repo.uri)\n                    + \"{} {}\\n\".format(repo.release, \" \".join(repo.groups))\n                ).encode(\"utf-8\")\n            )\n\n        self._repository_map[\"{}-{}-{}\".format(repo.repotype, repo.uri, repo.release)] = repo\n\n    def disable(self, repo: DebianRepository) -> None:\n        \"\"\"Remove a repository. Disable by default.\n\n        Args:\n          repo: a `DebianRepository` to disable\n        \"\"\"\n        searcher = \"{} {}{} {}\".format(\n            repo.repotype, repo.make_options_string(), repo.uri, repo.release\n        )\n\n        for line in fileinput.input(repo.filename, inplace=True):\n            if re.match(r\"^{}\\s\".format(re.escape(searcher)), line):\n                print(\"# {}\".format(line), end=\"\")\n            else:\n                print(line, end=\"\")\n\n        self._repository_map[\"{}-{}-{}\".format(repo.repotype, repo.uri, repo.release)] = repo\n", "any_charm.py": "import pathlib\nimport subprocess\nimport ops\nfrom any_charm_base import AnyCharmBase\nfrom ingress import IngressPerAppRequirer\nimport apt\n\nclass AnyCharm(AnyCharmBase):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.ingress = IngressPerAppRequirer(self, port=80, strip_prefix=True)\n\n    def start_server(self):\n        apt.update()\n        apt.add_package(package_names=\"apache2\")\n        www_dir = pathlib.Path(\"/var/www/html\")\n        file_path = www_dir / \"ok\"\n        file_path.parent.mkdir(exist_ok=True)\n        file_path.write_text(\"ok!\")\n        self.unit.status = ops.ActiveStatus(\"Server ready\")\n"}
